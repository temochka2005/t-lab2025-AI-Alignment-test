{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 1\n",
    "## Предлагается сначала просмотреть весь ноутбук и только потом запускать ячейки, поскольку последний блок с вычислением средней награды может быть запущен с использованием уже сохраненных на гите моделей, то есть без необходимости повторно запускать обучение.\n",
    "\n",
    "#### Запуск и работоспособность были проверены в Google Colab на GPU T4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде все пути к сохраненным моделям указаны в формате, в котором они предполагаются на Google Colab. При этом предлагается заменить \"  #YOUR PATH HERE \" на тот путь, в которой были установлены сохраненные модели, скачанные с гита. В случае работы в Google Colab они при загрузке на сервис автоматически попадают в путь \"/content/...\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок установки библиотек. \n",
    "\n",
    "\n",
    "Выбор конкретных версий обусловлен конфликтом совместимостей. Пришлось попотеть, чтобы оно завелось, поскольку без указаний конкретных версий на начальном этапе работы запуститься не удавалось(проблемы с tlr + transformer). Не исключено, что по итогу все заработает и с автоматической установкой версий, но на финальной версии кода это предположение не проверялось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers==0.19.3\n",
      "  Downloading diffusers-0.19.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting accelerate==0.23.0\n",
      "  Downloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sentence-transformers==2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.3) (8.6.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.3) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.3) (0.27.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.3) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.3) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.3) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.3) (0.5.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.3) (11.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.23.0) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.23.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.23.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.23.0) (2.5.1+cu124)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (4.47.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (4.67.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (0.20.1+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.19.3) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.19.3) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (3.1.5)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.23.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.23.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.23.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate==0.23.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate==0.23.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate==0.23.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate==0.23.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate==0.23.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate==0.23.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.23.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.23.0) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.21.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.19.3) (3.21.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.19.3) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.19.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.19.3) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.19.3) (2024.12.14)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.23.0) (3.0.2)\n",
      "Downloading diffusers-0.19.3-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=733e9d4fd93bf7d98e7565a83aa3c4b23405370329af257e3925ce70d673c467\n",
      "  Stored in directory: /root/.cache/pip/wheels/ff/27/bf/ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, diffusers, accelerate, sentence-transformers\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.32.2\n",
      "    Uninstalling diffusers-0.32.2:\n",
      "      Successfully uninstalled diffusers-0.32.2\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.2.1\n",
      "    Uninstalling accelerate-1.2.1:\n",
      "      Successfully uninstalled accelerate-1.2.1\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 3.3.1\n",
      "    Uninstalling sentence-transformers-3.3.1:\n",
      "      Successfully uninstalled sentence-transformers-3.3.1\n",
      "Successfully installed accelerate-0.23.0 diffusers-0.19.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sentence-transformers-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade \\\n",
    "    diffusers==0.19.3 \\\n",
    "    accelerate==0.23.0 \\\n",
    "    sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub==0.25.0\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.25.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.25.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.25.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.25.0) (2024.12.14)\n",
      "Downloading huggingface_hub-0.25.0-py3-none-any.whl (436 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/436.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.27.1\n",
      "    Uninstalling huggingface-hub-0.27.1:\n",
      "      Successfully uninstalled huggingface-hub-0.27.1\n",
      "Successfully installed huggingface_hub-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade huggingface_hub==0.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspec==2023.6.0\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting gcsfs==2023.6.0\n",
      "  Downloading gcsfs-2023.6.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2023.6.0) (3.11.11)\n",
      "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2023.6.0) (4.4.2)\n",
      "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2023.6.0) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs==2023.6.0) (1.2.1)\n",
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs==2023.6.0) (2.19.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gcsfs==2023.6.0) (2.32.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2023.6.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2023.6.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2023.6.0) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2023.6.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2023.6.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2023.6.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2023.6.0) (1.18.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2023.6.0) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2023.6.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2023.6.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs==2023.6.0) (1.3.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2023.6.0) (2.19.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2023.6.0) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2023.6.0) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2023.6.0) (1.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2023.6.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2023.6.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2023.6.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2023.6.0) (2024.12.14)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2023.6.0) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2023.6.0) (4.25.6)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2023.6.0) (1.26.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs==2023.6.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2023.6.0) (3.2.2)\n",
      "Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gcsfs-2023.6.0-py2.py3-none-any.whl (26 kB)\n",
      "Installing collected packages: fsspec, gcsfs\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: gcsfs\n",
      "    Found existing installation: gcsfs 2024.10.0\n",
      "    Uninstalling gcsfs-2024.10.0:\n",
      "      Successfully uninstalled gcsfs-2024.10.0\n",
      "Successfully installed fsspec-2023.6.0 gcsfs-2023.6.0\n"
     ]
    }
   ],
   "source": [
    "pip install fsspec==2023.6.0 gcsfs==2023.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
      "Collecting jax==0.4.27 (from jax[cuda]==0.4.27)\n",
      "  Downloading jax-0.4.27-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax==0.4.27->jax[cuda]==0.4.27) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from jax==0.4.27->jax[cuda]==0.4.27) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax==0.4.27->jax[cuda]==0.4.27) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax==0.4.27->jax[cuda]==0.4.27) (1.13.1)\n",
      "Collecting jaxlib==0.4.27+cuda12.cudnn89 (from jax[cuda]==0.4.27)\n",
      "  Downloading https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.27%2Bcuda12.cudnn89-cp311-cp311-manylinux2014_x86_64.whl (143.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jax-0.4.27-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jaxlib, jax\n",
      "  Attempting uninstall: jaxlib\n",
      "    Found existing installation: jaxlib 0.4.33\n",
      "    Uninstalling jaxlib-0.4.33:\n",
      "      Successfully uninstalled jaxlib-0.4.33\n",
      "  Attempting uninstall: jax\n",
      "    Found existing installation: jax 0.4.33\n",
      "    Uninstalling jax-0.4.33:\n",
      "      Successfully uninstalled jax-0.4.33\n",
      "Successfully installed jax-0.4.27 jaxlib-0.4.27+cuda12.cudnn89\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade \"jax[cuda]==0.4.27\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting trl==0.14.0\n",
      "  Downloading trl-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting peft==0.5.0\n",
      "  Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting accelerate>=0.34.0 (from trl==0.14.0)\n",
      "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl==0.14.0) (13.9.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.5.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.5.0) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.5.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.5.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.5.0) (2.5.1+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.5.0) (4.67.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.5.0) (0.5.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.5.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.5.0) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.14.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.14.0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.14.0) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.5.0) (3.0.2)\n",
      "Downloading trl-0.14.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets, accelerate, trl, peft\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.23.0\n",
      "    Uninstalling accelerate-0.23.0:\n",
      "      Successfully uninstalled accelerate-0.23.0\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.14.0\n",
      "    Uninstalling peft-0.14.0:\n",
      "      Successfully uninstalled peft-0.14.0\n",
      "Successfully installed accelerate-1.3.0 datasets-3.2.0 dill-0.3.8 multiprocess-0.70.16 peft-0.5.0 trl-0.14.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets trl==0.14.0 peft==0.5.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка SFT-модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_token.py:90: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee6fbcbee14417288707a9f8905e49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/861 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7666ce096ed487ebc5f2e823aeeae7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd328ed7c4284932850991feabb7d679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef44b547d7984f3da2dce24a4478dda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3452caa1af24164bbd7b1b4cd26bba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd979f3951e74099beaee250f38bdb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cc09e20afd4728b0f624b8bfa9cb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4369c8d96d384c5d875070fb923e8c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Подключаем GPU при наличии\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Модель и токенизатор\n",
    "sft_model_name = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "sft_model = AutoModelForCausalLM.from_pretrained(sft_model_name)\n",
    "sft_model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(sft_model_name, padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # на случай, если не определён pad_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок работы с датасетом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет и делим на train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 7810\n",
      "Validation size: 868\n",
      "{'prompt': Value(dtype='string', id=None), 'chosen': [{'content': Value(dtype='string', id=None), 'role': Value(dtype='string', id=None)}], 'chosen_rating': Value(dtype='float64', id=None), 'rejected': [{'content': Value(dtype='string', id=None), 'role': Value(dtype='string', id=None)}], 'rejected_rating': Value(dtype='float64', id=None)}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"esfrankel17/HelpSteer2_binarized\")\n",
    "ds = data[\"average_rating_split\"]\n",
    "\n",
    "split_data = ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split_data[\"train\"]\n",
    "validation_dataset = split_data[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Validation size:\", len(validation_dataset))\n",
    "print(train_dataset.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование данных датасета в формат, ожидаемый RewardTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample after transformation: {'prompt': '\"Delve into the multifaceted significance of a societal commitment to equality and mutual understanding in today’s world. Examine the historical developments that have led to the prioritization of these values and analyze their social, economic, and political ramifications in fostering inclusive communities. Discuss the psychological benefits that such a commitment brings to individuals and society as a whole, and explore the challenges and barriers that impede the realization of equality and understanding. Additionally, propose actionable strategies that could be implemented to overcome these obstacles, drawing on theoretical frameworks and empirical studies to support your analysis. This inquiry should encompass a broad perspective, highlighting the complex interplay between individual actions, societal norms, and institutional policies in advancing the cause of equality and understanding.\"', 'chosen': '\"Delve into the multifaceted significance of a societal commitment to equality and mutual understanding in today’s world. Examine the historical developments that have led to the prioritization of these values and analyze their social, economic, and political ramifications in fostering inclusive communities. Discuss the psychological benefits that such a commitment brings to individuals and society as a whole, and explore the challenges and barriers that impede the realization of equality and understanding. Additionally, propose actionable strategies that could be implemented to overcome these obstacles, drawing on theoretical frameworks and empirical studies to support your analysis. This inquiry should encompass a broad perspective, highlighting the complex interplay between individual actions, societal norms, and institutional policies in advancing the cause of equality and understanding.\"\\nUser: \"Delve into the multifaceted significance of a societal commitment to equality and mutual understanding in today’s world. Examine the historical developments that have led to the prioritization of these values and analyze their social, economic, and political ramifications in fostering inclusive communities. Discuss the psychological benefits that such a commitment brings to individuals and society as a whole, and explore the challenges and barriers that impede the realization of equality and understanding. Additionally, propose actionable strategies that could be implemented to overcome these obstacles, drawing on theoretical frameworks and empirical studies to support your analysis. This inquiry should encompass a broad perspective, highlighting the complex interplay between individual actions, societal norms, and institutional policies in advancing the cause of equality and understanding.\"\\nAssistant: Title: The Multifaceted Significance of a Societal Commitment to Equality and Mutual Understanding\\n\\nIntroduction:\\nA societal commitment to equality and mutual understanding is a complex and multifaceted concept that holds great significance in today\\'s world. This commitment has historical developments, social, economic, and political ramifications, and psychological benefits, as well as challenges and barriers that impede its realization. By examining these various aspects, we can gain a deeper understanding of the importance of promoting equality and mutual understanding in our societies.\\n\\nHistorical Developments:\\nThe prioritization of equality and mutual understanding has been a long-standing process, with roots in various social movements and historical events. The Enlightenment, the abolition of slavery, the civil rights movement, and the fight for women\\'s suffrage have all contributed to the increased emphasis on these values. These movements have shaped our understanding of human rights, democracy, and social justice, leading to a stronger commitment to promoting equality and mutual understanding in contemporary societies.\\n\\nRamifications of a Commitment to Equality and Mutual Understanding:\\n\\n1. Social: A commitment to equality and mutual understanding fosters inclusive communities by promoting respect for diversity and combating discrimination. This, in turn, leads to increased social cohesion, trust, and solidarity, as well as reduced social conflicts and tensions.\\n2. Economic: Equality and mutual understanding contribute to economic growth and development by ensuring equal opportunities for all members of society. This leads to a more efficient allocation of resources and a more innovative and productive workforce, benefiting both individuals and society as a whole.\\n3. Political: A commitment to equality and mutual understanding is essential for the functioning of democratic societies, as it promotes participation, representation, and accountability. Additionally, it contributes to the stability and resilience of political institutions, as well as the legitimacy of the political system.\\n\\nPsychological Benefits:\\nThe pursuit of equality and mutual understanding has psychological benefits for both individuals and society. At the individual level, it contributes to improved mental health, well-being, and life satisfaction. At the societal level, it fosters a sense of collective identity, social trust, and solidarity, leading to more stable and harmonious communities.\\n\\nChallenges and Barriers:\\nDespite the apparent benefits of a societal commitment to equality and mutual understanding, there are several challenges and barriers that impede its realization. These include:\\n\\n1. Structural barriers: Inequality is often perpetuated by structural factors such as discrimination, social exclusion, and unequal access to resources and opportunities.\\n2. Psychological barriers: Prejudice, stereotypes, and biases can hinder the development of mutual understanding and contribute to the perpetuation of inequality.\\n3. Institutional barriers: Inequality can be reinforced by institutional factors such as laws, policies, and practices that favor certain groups over others.\\n4. Cultural barriers: Cultural norms and values that prioritize individualism, competition, and self-interest can undermine efforts to promote equality and mutual understanding.\\n\\nStrategies for Overcoming Obstacles:\\nTo overcome these challenges and barriers, several strategies can be implemented, including:\\n\\n1. Education: Promoting awareness and understanding of diversity, inequality, and social justice through education can help challenge stereotypes and biases and foster a commitment to equality and mutual understanding.\\n2. Legislation: Implementing and enforcing laws and policies that promote equality and combat discrimination can help address structural barriers to equality.\\n3. Institutions: Transforming institutions to be more inclusive, equitable, and responsive to diverse needs can help overcome institutional barriers to equality.\\n4. Community engagement: Encouraging community participation and engagement in decision-making processes can help challenge cultural barriers to equality and mutual understanding.\\n\\nConclusion:\\nThe societal commitment to equality and mutual understanding is a complex and multifaceted concept with significant social, economic, and political ramifications, as well as psychological benefits. By understanding the historical developments that have led to the prioritization of these values, as well as the challenges and barriers that impede their realization, we can propose actionable strategies for overcoming obstacles and advancing the cause of equality and understanding. This requires a broad perspective that encompasses individual actions, societal norms, and institutional policies, working together to create a more inclusive, equitable, and harmonious world.', 'rejected': '\"Delve into the multifaceted significance of a societal commitment to equality and mutual understanding in today’s world. Examine the historical developments that have led to the prioritization of these values and analyze their social, economic, and political ramifications in fostering inclusive communities. Discuss the psychological benefits that such a commitment brings to individuals and society as a whole, and explore the challenges and barriers that impede the realization of equality and understanding. Additionally, propose actionable strategies that could be implemented to overcome these obstacles, drawing on theoretical frameworks and empirical studies to support your analysis. This inquiry should encompass a broad perspective, highlighting the complex interplay between individual actions, societal norms, and institutional policies in advancing the cause of equality and understanding.\"\\nUser: \"Delve into the multifaceted significance of a societal commitment to equality and mutual understanding in today’s world. Examine the historical developments that have led to the prioritization of these values and analyze their social, economic, and political ramifications in fostering inclusive communities. Discuss the psychological benefits that such a commitment brings to individuals and society as a whole, and explore the challenges and barriers that impede the realization of equality and understanding. Additionally, propose actionable strategies that could be implemented to overcome these obstacles, drawing on theoretical frameworks and empirical studies to support your analysis. This inquiry should encompass a broad perspective, highlighting the complex interplay between individual actions, societal norms, and institutional policies in advancing the cause of equality and understanding.\"\\nAssistant: A commitment to equality and mutual understanding is foundational to building resilient, inclusive communities in today\\'s global society. Historical movements and struggles, from civil rights to gender equality and beyond, have underscored the necessity of these values, shaping a collective consciousness towards social justice and equity.\\n\\nThe prioritization of equality and understanding yields significant social benefits, fostering environments where diverse perspectives are valued and collaboration flourishes. Economically, such inclusivity can drive innovation and growth by ensuring all individuals have the opportunity to contribute to the workforce and society. Politically, it promotes stability and peace by addressing grievances and reducing the grounds for conflict.\\n\\nOn a psychological level, the emphasis on equality and understanding enhances individual well-being by creating a sense of belonging and reducing instances of discrimination and social exclusion. This, in turn, contributes to the overall health of society by building social cohesion and trust among its members.\\n\\nHowever, achieving true equality and understanding faces numerous challenges, including systemic discrimination, cultural biases, and economic disparities. Overcoming these obstacles requires a multifaceted approach, encompassing education reform to promote inclusivity from an early age, policy changes to address systemic inequalities, and initiatives to increase awareness and empathy among the populace.\\n\\nImplementing these strategies necessitates a collaborative effort among governments, organizations, and individuals. Drawing on theoretical frameworks such as social constructivism and empirical studies on social inclusion, actionable steps include enhancing representation in all societal sectors, enforcing anti-discrimination laws, and fostering dialogue among diverse groups.\\n\\nIn conclusion, the journey towards equality and mutual understanding is complex and ongoing. It requires a concerted effort to dismantle existing barriers and build a society that values and practices inclusivity at every level, thereby enriching the fabric of communities worldwide.'}\n",
      "Dataset({\n",
      "    features: ['prompt', 'chosen', 'rejected'],\n",
      "    num_rows: 7810\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#  Вспомогательная функция, склеивающая список [ {role, content}, ... ] в одну строку\n",
    "def merge_messages(messages):\n",
    "    \"\"\"\n",
    "    Преобразуем list of dicts [{\"role\": \"...\", \"content\": \"...\"}] в одну строку.\n",
    "    \"\"\"\n",
    "    text_list = []\n",
    "    for m in messages:\n",
    "        role = m.get(\"role\", \"\")\n",
    "        content = m.get(\"content\", \"\")\n",
    "        text_list.append(f\"{role.capitalize()}: {content}\")\n",
    "    return \"\\n\".join(text_list)\n",
    "\n",
    "# Преобразуем пример к формату, ожидаемому RewardTrainer\n",
    "def transform_to_reward_format(example):\n",
    "    \"\"\"\n",
    "    Должны вернуть словарь с тремя ключами:\n",
    "      \"prompt\": str,\n",
    "      \"chosen\": str,\n",
    "      \"rejected\": str\n",
    "    \"\"\"\n",
    "    prompt_text = example[\"prompt\"]  # уже строка\n",
    "    chosen_text = merge_messages(example[\"chosen\"])\n",
    "    rejected_text = merge_messages(example[\"rejected\"])\n",
    "\n",
    "    # Склеиваем prompt и выбранный/отвергнутый ответ\n",
    "    chosen_full = prompt_text + \"\\n\" + chosen_text\n",
    "    rejected_full = prompt_text + \"\\n\" + rejected_text\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt_text,\n",
    "        \"chosen\": chosen_full,\n",
    "        \"rejected\": rejected_full\n",
    "    }\n",
    "\n",
    "# Применяем map с remove_columns, чтобы оставить только нужные поля.\n",
    "#    batched=False: transform_to_reward_format обрабатывает ровно один пример за раз.\n",
    "train_dataset = train_dataset.map(\n",
    "    transform_to_reward_format,\n",
    "    batched=False,\n",
    "    remove_columns=train_dataset.column_names  # убираем остальные колонки\n",
    ")\n",
    "validation_dataset = validation_dataset.map(\n",
    "    transform_to_reward_format,\n",
    "    batched=False,\n",
    "    remove_columns=validation_dataset.column_names\n",
    ")\n",
    "\n",
    "# Проверяем структуру\n",
    "print(\"Train sample after transformation:\", train_dataset[0])\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем модель для RM, совпадающую с базовой, и настраиваем Trainer\n",
    "Для запуска ячеек в этом блоке обязательно запустить все, что было выше в этом ноутбуке. Этот блок нужен, чтобы получить RM, которую мы будем использовать позже. Поскольку процесс обучения не происходит мгновенно, предлагается пользоваться моделью, полученной с помощью этого кода и уже сохраненной на гите в папке \"rm-checkpoints-final\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import RewardTrainer, RewardConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Снова инициализируем модель\n",
    "reward_model_name = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    reward_model_name,\n",
    "    num_labels=1\n",
    ")\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(reward_model_name)\n",
    "\n",
    "\n",
    "# Конфигурация обучения\n",
    "training_args = RewardConfig(\n",
    "    output_dir=\"./reward_model\",\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    fp16=True,\n",
    "    max_length=512,  # Ограничиваем максимальную длину, чтобы избежать Out of Memory\n",
    ")\n",
    "\n",
    "# Инициализация RewardTrainer\n",
    "trainer = RewardTrainer(\n",
    "    model=reward_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск обучения\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# После обучения — сохраняем модель\n",
    "trainer.save_model(\"./rm-checkpoints-final\")\n",
    "# в случае запуска в Google Colab путь сохранения выглядит так: \"/content/rm-checkpoints-final\"\n",
    "print(\"Reward Model training is complete and saved to rm-checkpoints-final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация метода из статьи\n",
    "Для работы этих ячеек нужно запустить блок с загрузой датасета. Чтобы посчитать среднюю награду запускать этот блок нет необходимости, потому что модели уже будут сохранены в нужных папках на гите."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. Загрузка RM из сохранённых чекпоинтов и установка устройства\n",
    "# =============================================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Загружаем Reward Model (RM) из сохранённого пути\n",
    "reward_model_path = #YOUR PATH HERE\n",
    "    # в случае запуска в Google Colab: \"/content/rm-checkpoints-final\"\n",
    "\n",
    "\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    reward_model_path,\n",
    "    num_labels=1  # модель для регрессии (скалярная оценка)\n",
    ")\n",
    "reward_model.to(device)\n",
    "reward_model.eval()  # отключаем dropout и т.д. для оценки\n",
    "\n",
    "# Для RM используем отдельный токенизатор (можно использовать и тот же, если подходит)\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(reward_model_path)\n",
    "if reward_tokenizer.pad_token is None:\n",
    "    reward_tokenizer.pad_token = reward_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. Гиперпараметры и оптимизатор\n",
    "# =============================================================================\n",
    "batch_size = 4            \n",
    "num_iterations = 30\n",
    "max_new_tokens = 50       # максимальное число генерируемых токенов (отвечает за длину ответа)\n",
    "alpha = 0.9               # коэффициент для moving average baseline\n",
    "learning_rate = 1e-5      # скорость обучения для SFT-модели\n",
    "\n",
    "optimizer = torch.optim.AdamW(sft_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Подготовка DataLoader для датасета\n",
    "# =============================================================================\n",
    "\n",
    "# Предполагается, что train_dataset (HuggingFace Dataset) уже подготовлен в запущенных нами ячейках\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Чтобы цикл был бесконечным, используем итератор, циклично перебирающий датасет:\n",
    "data_iter = iter(itertools.cycle(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. Вспомогательная функция для вычисления log-вероятности сгенерированного ответа\n",
    "# =============================================================================\n",
    "\n",
    "def compute_log_prob(prompt, generated_ids):\n",
    "    \"\"\"\n",
    "    Вычисляет суммарную log-вероятность сгенерированных токенов (условно от prompt).\n",
    "\n",
    "    Аргументы:\n",
    "      prompt: str – исходный текст запроса.\n",
    "      generated_ids: тензор [1, T] – результат работы sft_model.generate(),\n",
    "                     который содержит prompt в начале и сгенерированный ответ.\n",
    "\n",
    "    Алгоритм:\n",
    "      - Определяем длину токенизированного prompt (prompt_length).\n",
    "      - Выполняем проход модели (teacher forcing) по полученной последовательности.\n",
    "      - С учётом сдвига: первые сгенерированные токены (токены с позиции prompt_length)\n",
    "        предсказываются логитами с позиции prompt_length-1.\n",
    "      - Суммируем log-вероятности по токенам сгенерированного ответа.\n",
    "    \"\"\"\n",
    "    # Токенизируем prompt для определения его длины\n",
    "    prompt_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    prompt_length = prompt_ids.size(1)\n",
    "\n",
    "    # generated_ids уже находится на device, имеет форму [1, T]\n",
    "    full_ids = generated_ids\n",
    "    T = full_ids.size(1)\n",
    "\n",
    "    # Если по какой-то причине сгенерировано меньше токенов, чем длина prompt:\n",
    "    if T - prompt_length <= 0:\n",
    "        return torch.tensor(0.0, device=device)\n",
    "\n",
    "    # Прямой проход модели (teacher forcing) для вычисления логитов\n",
    "    outputs = sft_model(full_ids)\n",
    "    logits = outputs.logits  # форма [1, T, vocab_size]\n",
    "\n",
    "    # Вычисляем log_softmax для получения log-вероятностей\n",
    "    log_probs = torch.log_softmax(logits, dim=-1)  # [1, T, vocab_size]\n",
    "\n",
    "    # Для вычисления log p(y|x):\n",
    "    # Сгенерированные токены – это токены с позиций prompt_length ... T-1,\n",
    "    # а их вероятность предсказывается логитами с позиций prompt_length-1 ... T-2.\n",
    "    pred_logits = log_probs[:, prompt_length - 1:T - 1, :]  # [1, T - prompt_length, vocab_size]\n",
    "    target_tokens = full_ids[:, prompt_length:]                # [1, T - prompt_length]\n",
    "\n",
    "    # Извлекаем log-вероятность для каждого целевого токена\n",
    "    token_log_probs = pred_logits.gather(2, target_tokens.unsqueeze(-1)).squeeze(-1)  # [1, T - prompt_length]\n",
    "    sum_log_prob = token_log_probs.sum()  # суммарная log-вероятность\n",
    "    return sum_log_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало обучения REINFORCE w/ baseline...\n",
      "Step 10/30 | Loss: 44.1435 | Avg Reward: 1.2274 | Baseline: 0.6652\n",
      "Step 20/30 | Loss: 4.2267 | Avg Reward: 1.0036 | Baseline: 0.7408\n",
      "Step 30/30 | Loss: -8.8195 | Avg Reward: 0.5787 | Baseline: 0.7114\n",
      "Обучение завершено.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. Основной цикл обучения REINFORCE w/ baseline\n",
    "# =============================================================================\n",
    "\n",
    "# Инициализируем baseline (начальное значение, например, 0)\n",
    "baseline = 0.0\n",
    "\n",
    "print(\"Начало обучения REINFORCE w/ baseline...\")\n",
    "for step in range(num_iterations):\n",
    "    batch = next(data_iter)  # batch — словарь с ключами \"prompt\", \"chosen\", и т.д.\n",
    "\n",
    "    batch_loss = 0.0\n",
    "    batch_rewards = []  # для вычисления среднего значения награды в батче\n",
    "\n",
    "    # Обрабатываем каждый пример в батче, итерируясь по индексам\n",
    "    for i in range(len(batch[\"prompt\"])):\n",
    "        prompt_text = batch[\"prompt\"][i]\n",
    "\n",
    "        # 1. Генерация ответа моделью SFT\n",
    "        encoded_prompt = tokenizer(prompt_text, return_tensors=\"pt\", truncation=True).to(device)\n",
    "        generated_ids = sft_model.generate(\n",
    "            input_ids=encoded_prompt.input_ids,\n",
    "            attention_mask=encoded_prompt.attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,       # сэмплирование для стохастичности\n",
    "            top_k=50,             # можно подобрать другие параметры сэмплирования\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # 2. Оценка награды с помощью RM (без backprop через RM)\n",
    "        with torch.no_grad():\n",
    "            tokenized_reward = reward_tokenizer(\n",
    "                generated_text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            ).to(device)\n",
    "            reward_output = reward_model(**tokenized_reward)\n",
    "            # Предполагаем, что выход RM – скаляр (логит) награды\n",
    "            reward_value = reward_output.logits.mean()  # tensor-значение\n",
    "        batch_rewards.append(reward_value.item())\n",
    "\n",
    "        # 3. Вычисление log-вероятности сгенерированного ответа\n",
    "        log_prob = compute_log_prob(prompt_text, generated_ids)  # дифференцируемая величина\n",
    "\n",
    "        # 4. Вычисление Advantage = (reward - baseline)\n",
    "        advantage = reward_value - baseline  # reward_value – тензор, baseline – float\n",
    "\n",
    "        # 5. Функция потерь для данного примера: -advantage * log_prob\n",
    "        sample_loss = - advantage * log_prob\n",
    "        batch_loss = batch_loss + sample_loss\n",
    "\n",
    "    # Усредняем потери по батчу\n",
    "    batch_loss = batch_loss / batch_size\n",
    "\n",
    "    # Обновляем параметры SFT-модели\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Обновляем baseline (скользящее среднее)\n",
    "    batch_mean_reward = sum(batch_rewards) / len(batch_rewards)\n",
    "    baseline = alpha * baseline + (1 - alpha) * batch_mean_reward\n",
    "\n",
    "    # Логирование каждые 10 шагов\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(f\"Step {step+1}/{num_iterations} | Loss: {batch_loss.item():.4f} | \"\n",
    "              f\"Avg Reward: {batch_mean_reward:.4f} | Baseline: {baseline:.4f}\")\n",
    "\n",
    "print(\"Обучение завершено.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sft-rlhf-reinforce-trained/tokenizer_config.json',\n",
       " './sft-rlhf-reinforce-trained/special_tokens_map.json',\n",
       " './sft-rlhf-reinforce-trained/vocab.json',\n",
       " './sft-rlhf-reinforce-trained/merges.txt',\n",
       " './sft-rlhf-reinforce-trained/added_tokens.json',\n",
       " './sft-rlhf-reinforce-trained/tokenizer.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Сохранение модели на тот случай, чтобы можно было независимо от верхних ячеек запускать оценку средней награды\n",
    "sft_model.save_pretrained(\"./sft-rlhf-reinforce-trained\")\n",
    "tokenizer.save_pretrained(\"./sft-rlhf-reinforce-trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценим среднюю награду моделей на validation наборе.\n",
    "Эти ячейки можно запускать независимо от верхних блоков, но при условии запуска ячеек с датасетом. Без запуска блока датасета работать не будет. Здесь используются модели, которые мы уже получили(сохранили) в верхних блоках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Функция для оценки средней награды модели на validation наборе\n",
    "def evaluate_avg_reward(model, tokenizer, dataset,\n",
    "                        reward_model, reward_tokenizer,\n",
    "                        max_new_tokens=50):\n",
    "    model.eval()\n",
    "    rewards = []\n",
    "    # Пройдемся по всем примерам в validation наборе\n",
    "    for sample in dataset:\n",
    "        prompt_text = sample[\"prompt\"]\n",
    "        encoded = tokenizer(prompt_text, return_tensors=\"pt\",\n",
    "                            truncation=True).to(device)\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=encoded.input_ids,\n",
    "            attention_mask=encoded.attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        with torch.no_grad():\n",
    "            tokenized_reward = reward_tokenizer(\n",
    "                generated_text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            ).to(device)\n",
    "\n",
    "            reward_output = reward_model(**tokenized_reward)\n",
    "            # Предполагаем, что reward_model возвращает логиты (скаляр)\n",
    "            reward_value = reward_output.logits.mean().item()\n",
    "            \n",
    "        rewards.append(reward_value)\n",
    "\n",
    "    avg_reward = sum(rewards) / len(rewards)\n",
    "\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Загрузка исходной SFT модели (базовая)\n",
    "# -------------------------------\n",
    "original_sft_model_name = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "original_sft_model = AutoModelForCausalLM.from_pretrained(original_sft_model_name)\n",
    "original_sft_model.to(device)\n",
    "original_sft_model.eval()\n",
    "\n",
    "# -------------------------------\n",
    "# RLHF модель – текущая sft_model после дообучения REINFORCE\n",
    "# -------------------------------\n",
    "# Если мы запускали ячейки выше, то sft_model уже дообучена и находится в памяти.\n",
    "# В любом случае есть сохранение этой модели в папке \"sft-rlhf-reinforce-trained\" на гите, им мы и воспользуемся:\n",
    "sft_model = AutoModelForCausalLM.from_pretrained( #YOUR PATH HERE\n",
    "    # в случае запуска в Google Colab: \"/content/sft-rlhf-reinforce-trained\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(#YOUR PATH HERE\n",
    "    # в случае запуска в Google Colab: \"/content/sft-rlhf-reinforce-trained\"\n",
    "                                          , padding_side=\"left\")\n",
    "sft_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка средней награды на validation наборе:\n",
      "Средняя награда базовой (SFT) модели: 0.6524484621592656\n",
      "Средняя награда RLHF модели: 0.7051663907064546\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем среднюю награду на validation наборе для каждой модели\n",
    "print(\"Оценка средней награды на validation наборе:\")\n",
    "\n",
    "avg_reward_sft = evaluate_avg_reward(\n",
    "    model=original_sft_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=validation_dataset,       # validation_dataset должен быть, поэтому и нужно запустить блок с загрузкой датасета\n",
    "    reward_model=reward_model,\n",
    "    reward_tokenizer=reward_tokenizer,\n",
    "    max_new_tokens=50\n",
    ")\n",
    "print(\"Средняя награда базовой (SFT) модели:\", avg_reward_sft)\n",
    "\n",
    "avg_reward_rlhf = evaluate_avg_reward(\n",
    "    model=sft_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=validation_dataset,\n",
    "    reward_model=reward_model,\n",
    "    reward_tokenizer=reward_tokenizer,\n",
    "    max_new_tokens=50\n",
    ")\n",
    "print(\"Средняя награда RLHF модели:\", avg_reward_rlhf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок с рассмотрением KL-метрики\n",
    "Эти ячейки можно запускать независимо от верхних блоков, но при условии запуска ячеек с датасетом. Без запуска блока датасета работать не будет. Здесь используются модели, которые мы уже получили(сохранили) в верхних блоках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_kl_for_prompt(prompt, base_model, new_model, tokenizer, max_length=512):\n",
    "    \"\"\"\n",
    "    Вычисляет KL-дивергенцию между распределениями токенов,\n",
    "    генерируемыми базовой (base_model) и новой (new_model) моделями,\n",
    "    для данного промпта.\n",
    "    \n",
    "    Аргументы:\n",
    "      prompt (str): входной текст.\n",
    "      base_model: исходная (SFT) модель.\n",
    "      new_model: дообученная (RLHF) модель.\n",
    "      tokenizer: токенизатор, используемый обеими моделями.\n",
    "      max_length (int): максимальная длина входной последовательности.\n",
    "      \n",
    "    Возвращает:\n",
    "      kl_div (float): усреднённая KL-дивергенция.\n",
    "    \"\"\"\n",
    "    # Токенизируем промпт\n",
    "    encoded = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Получаем логиты обеих моделей (форма: [batch_size, seq_length, vocab_size])\n",
    "        outputs_base = base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        outputs_new = new_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits_base = outputs_base.logits\n",
    "    logits_new = outputs_new.logits\n",
    "    \n",
    "    # Преобразуем логиты в распределения вероятностей по каждому токену\n",
    "    p_base = F.softmax(logits_base, dim=-1)\n",
    "    p_new = F.softmax(logits_new, dim=-1)\n",
    "    \n",
    "    # Вычисляем log‑вероятности (с небольшой константой для стабильности)\n",
    "    log_p_base = torch.log(p_base + 1e-10)\n",
    "    log_p_new = torch.log(p_new + 1e-10)\n",
    "    \n",
    "    # KL-дивергенция по формуле для каждого токена:\n",
    "    # KL(P || Q) = sum_v  P(v) * (log P(v) - log Q(v))\n",
    "    kl_per_token = (p_base * (log_p_base - log_p_new)).sum(dim=-1)  # [batch_size, seq_length]\n",
    "    \n",
    "    # Усредняем KL по токенам и по батчу (в нашем случае batch_size=1)\n",
    "    kl_div = kl_per_token.mean()\n",
    "    return kl_div.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(49152, 576, padding_idx=2)\n",
       "    (layers): ModuleList(\n",
       "      (0-29): 30 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "          (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "          (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "          (up_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "          (down_proj): Linear(in_features=1536, out_features=576, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Загрузка исходной SFT модели (базовая)\n",
    "# -------------------------------\n",
    "original_sft_model_name = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "original_sft_model = AutoModelForCausalLM.from_pretrained(original_sft_model_name)\n",
    "original_sft_model.to(device)\n",
    "original_sft_model.eval()\n",
    "\n",
    "# -------------------------------\n",
    "# RLHF модель – текущая sft_model после дообучения REINFORCE\n",
    "# -------------------------------\n",
    "# Если мы запускали ячейки выше, то sft_model уже дообучена и находится в памяти.\n",
    "# В любом случае есть сохранение этой модели в папке \"sft-rlhf-reinforce-trained\" на гите, чем мы и воспользуемся:\n",
    "sft_model = AutoModelForCausalLM.from_pretrained(#YOUR PATH HERE\n",
    "    # в случае запуска в Google Colab: \"/content/sft-rlhf-reinforce-trained\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(#YOUR PATH HERE\n",
    "    # в случае запуска в Google Colab: \"/content/sft-rlhf-reinforce-trained\"\n",
    "    , padding_side=\"left\")\n",
    "sft_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL-дивергенция для промпта how do you prepare potatos for frying: 0.0042\n"
     ]
    }
   ],
   "source": [
    "# Предположим, что:\n",
    "# - original_sft_model — базовая SFT модель,\n",
    "# - sft_model — дообученная RLHF модель,\n",
    "# - tokenizer — общий токенизатор,\n",
    "\n",
    "prompt_example = \"how do you prepare potatos for frying\"\n",
    "kl_value = compute_kl_for_prompt(\n",
    "    prompt=prompt_example,\n",
    "    base_model=original_sft_model,\n",
    "    new_model=sft_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512\n",
    ")\n",
    "print(f\"KL-дивергенция для промпта {prompt_example}: {kl_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def compute_avg_kl(validation_dataset, base_model, new_model, tokenizer, max_length=512, max_examples=None):\n",
    "    \"\"\"\n",
    "    Вычисляет среднюю KL-дивергенцию между базовой (base_model)\n",
    "    и новой (new_model) моделями для всех промптов из validation_dataset.\n",
    "    \n",
    "    Аргументы:\n",
    "      validation_dataset: список или HuggingFace Dataset, содержащий промпты (ключ \"prompt\").\n",
    "      base_model: исходная SFT модель.\n",
    "      new_model: RLHF модель.\n",
    "      tokenizer: токенизатор для обеих моделей.\n",
    "      max_length: максимальная длина токенизированного ввода.\n",
    "      max_examples: если задано, ограничивает число примеров (для ускорения).\n",
    "      \n",
    "    Возвращает:\n",
    "      Среднее значение KL-дивергенции по всем примерам.\n",
    "    \"\"\"\n",
    "    kl_values = []\n",
    "    \n",
    "    # Если задано ограничение на число примеров, берем срез датасета\n",
    "    if max_examples is not None:\n",
    "        dataset = validation_dataset.select(range(max_examples)) if hasattr(validation_dataset, \"select\") else validation_dataset[:max_examples]\n",
    "    else:\n",
    "        dataset = validation_dataset\n",
    "\n",
    "    for sample in tqdm(dataset, desc=\"Вычисление KL для промптов\", total=len(dataset)):\n",
    "        prompt = sample[\"prompt\"]\n",
    "        kl = compute_kl_for_prompt(prompt, base_model, new_model, tokenizer, max_length)\n",
    "        kl_values.append(kl)\n",
    "    \n",
    "    avg_kl = sum(kl_values) / len(kl_values)\n",
    "    return avg_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c522613c7947d6b2f64bc638bd4e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Вычисление KL для промптов:   0%|          | 0/868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя KL-дивергенция по валидационным промптам: 0.0101\n"
     ]
    }
   ],
   "source": [
    "avg_kl = compute_avg_kl(\n",
    "    validation_dataset=validation_dataset,\n",
    "    base_model=original_sft_model,\n",
    "    new_model=sft_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    max_examples=None  # задаем None, если нужно обработать весь датасет\n",
    ")\n",
    "\n",
    "print(f\"Средняя KL-дивергенция по валидационным промптам: {avg_kl:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обуждение результатов хранится в виде отчета на гите."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
