{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 2 \n",
    "## Предлагается сначала просмотреть весь ноутбук и только потом запускать ячейки, поскольку последний блок с вычислением средней награды может быть запущен с использованием уже сохраненных на гите моделей, то есть без необходимости повторно запускать обучение.\n",
    "\n",
    "#### Запуск и работоспособность были проверены в Google Colab на GPU T4. Ожидается, что все требуемые библиотеки уже установлены в окружении из ноутбука Level1.ipynb , но на всякий случай продублируем здесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок установки библиотек. \n",
    "(Полный дубликат из Level1, хотя trl в этом ноутбуке не используется) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade \\\n",
    "    diffusers==0.19.3 \\\n",
    "    accelerate==0.23.0 \\\n",
    "    sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade huggingface_hub==0.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fsspec==2023.6.0 gcsfs==2023.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade \"jax[cuda]==0.4.27\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers datasets trl==0.14.0 peft==0.5.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним, что в коде все пути к сохраненным моделям указаны в формате, в котором они предполагаются на Google Colab. При этом предлагается заменить \"  #YOUR PATH HERE \" на тот путь, в которой были установлены сохраненные модели, скачанные с гита. В случае работы в Google Colab они при загрузке автоматически попадают в путь \"/content/...\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет и делим на train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 7810\n",
      "Validation size: 868\n",
      "{'prompt': Value(dtype='string', id=None), 'chosen': [{'content': Value(dtype='string', id=None), 'role': Value(dtype='string', id=None)}], 'chosen_rating': Value(dtype='float64', id=None), 'rejected': [{'content': Value(dtype='string', id=None), 'role': Value(dtype='string', id=None)}], 'rejected_rating': Value(dtype='float64', id=None)}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"esfrankel17/HelpSteer2_binarized\")\n",
    "ds = data[\"average_rating_split\"]\n",
    "\n",
    "split_data = ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split_data[\"train\"]\n",
    "validation_dataset = split_data[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Validation size:\", len(validation_dataset))\n",
    "print(train_dataset.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок с подготовкой RM, которая выдаёт не скалярную оценку, а распределение вероятности поверх дискретных оценок. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. Настройки и гиперпараметры (совпадают с Level 1)\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 1         # подберите в соответствии с ресурсами\n",
    "learning_rate = 5e-5\n",
    "num_epochs = 1         # можно увеличить число эпох\n",
    "max_length = 64       # максимальная длина токенизированного текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. Функции для преобразования сообщений\n",
    "# =============================================================================\n",
    "def merge_messages(messages):\n",
    "    \"\"\"\n",
    "    Преобразуем список словарей [{\"role\": ..., \"content\": ...}, ...]\n",
    "    в строку вида:\n",
    "        \"User: ...\\nAssistant: ...\\n...\"\n",
    "    \"\"\"\n",
    "    text_list = []\n",
    "    for m in messages:\n",
    "        role = m.get(\"role\", \"\")\n",
    "        content = m.get(\"content\", \"\")\n",
    "        text_list.append(f\"{role.capitalize()}: {content}\")\n",
    "    return \"\\n\".join(text_list)\n",
    "\n",
    "def process_item(item):\n",
    "    \"\"\"\n",
    "    Если item уже строка — возвращаем её,\n",
    "    если это список (например, список сообщений) — объединяем с помощью merge_messages,\n",
    "    иначе приводим к строке.\n",
    "    \"\"\"\n",
    "    if isinstance(item, str):\n",
    "        return item\n",
    "    elif isinstance(item, list):\n",
    "        return merge_messages(item)\n",
    "    else:\n",
    "        return str(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Загрузка модели Reward Model с 10 выходными логитами\n",
    "# =============================================================================\n",
    "\n",
    "reward_model_name = \"HuggingFaceTB/SmolLM2-135M-Instruct\"  # имя или путь к модели\n",
    "# Загружаем модель для классификации с 10 классами (оценки 1..10)\n",
    "model_rm = AutoModelForSequenceClassification.from_pretrained(\n",
    "    reward_model_name,\n",
    "    num_labels=10\n",
    ")\n",
    "model_rm.to(device)\n",
    "model_rm.train()\n",
    "\n",
    "# Токенизатор для модели RM\n",
    "tokenizer_rm = AutoTokenizer.from_pretrained(reward_model_name)\n",
    "if tokenizer_rm.pad_token is None:\n",
    "    tokenizer_rm.pad_token = tokenizer_rm.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. Подготовка DataLoader\n",
    "# =============================================================================\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Каждый элемент batch — словарь с ключами, например, \"prompt\", \"chosen\", \"rejected\", ...\n",
    "    Для ключей \"chosen\" и \"rejected\" применяем process_item для преобразования в строку.\n",
    "    \"\"\"\n",
    "    collated = {}\n",
    "    for key in batch[0].keys():\n",
    "        if key in [\"chosen\", \"rejected\"]:\n",
    "            collated[key] = [process_item(sample[key]) for sample in batch]\n",
    "        else:\n",
    "            collated[key] = [sample[key] for sample in batch]\n",
    "    return collated\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_rm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HuggingFaceTB/SmolLM2-135M-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало обучения Reward Model с распределением оценок...\n",
      "Epoch 1, Step 0, Loss: 1.1581\n",
      "Epoch 1, Step 10, Loss: 1.9186\n",
      "Epoch 1, Step 20, Loss: 1.1511\n",
      "Epoch 1, Step 30, Loss: 0.9796\n",
      "Epoch 1, Step 40, Loss: 1.6202\n",
      "Epoch 1, Step 50, Loss: 1.1592\n",
      "Epoch 1, Step 60, Loss: 1.1645\n",
      "Epoch 1, Step 70, Loss: 1.1340\n",
      "Epoch 1, Step 80, Loss: 1.2958\n",
      "Epoch 1, Step 90, Loss: 0.9211\n",
      "Epoch 1, Step 100, Loss: 0.1259\n",
      "Epoch 1, Step 110, Loss: 1.2483\n",
      "Epoch 1, Step 120, Loss: 0.9974\n",
      "Epoch 1, Step 130, Loss: 0.5602\n",
      "Epoch 1, Step 140, Loss: 0.5220\n",
      "Epoch 1, Step 150, Loss: 0.3325\n",
      "Epoch 1, Step 160, Loss: 0.9945\n",
      "Epoch 1, Step 170, Loss: 0.4272\n",
      "Epoch 1, Step 180, Loss: 0.5015\n",
      "Epoch 1, Step 190, Loss: 1.4736\n",
      "Epoch 1, Step 200, Loss: 0.8810\n",
      "Epoch 1, Step 210, Loss: 0.9783\n",
      "Epoch 1, Step 220, Loss: 1.0180\n",
      "Epoch 1, Step 230, Loss: 0.8734\n",
      "Epoch 1, Step 240, Loss: 0.7269\n",
      "Epoch 1, Step 250, Loss: 1.1481\n",
      "Epoch 1, Step 260, Loss: 0.9211\n",
      "Epoch 1, Step 280, Loss: 0.8411\n",
      "Epoch 1, Step 290, Loss: 0.8735\n",
      "Epoch 1, Step 300, Loss: 0.8886\n",
      "Epoch 1, Step 310, Loss: 0.6158\n",
      "Epoch 1, Step 320, Loss: 0.8790\n",
      "Epoch 1, Step 330, Loss: 0.9677\n",
      "Epoch 1, Step 340, Loss: 0.9450\n",
      "Epoch 1, Step 350, Loss: 0.9317\n",
      "Epoch 1, Step 360, Loss: 0.3727\n",
      "Epoch 1, Step 370, Loss: 0.8540\n",
      "Epoch 1, Step 380, Loss: 1.3410\n",
      "Epoch 1, Step 390, Loss: 1.1027\n",
      "Epoch 1, Step 400, Loss: 1.0990\n",
      "Epoch 1, Step 410, Loss: 0.9276\n",
      "Epoch 1, Step 420, Loss: 0.8420\n",
      "Epoch 1, Step 430, Loss: 1.5609\n",
      "Epoch 1, Step 440, Loss: 0.8025\n",
      "Epoch 1, Step 450, Loss: 0.8901\n",
      "Epoch 1, Step 460, Loss: 0.8073\n",
      "Epoch 1, Step 470, Loss: 0.8375\n",
      "Epoch 1, Step 480, Loss: 0.8542\n",
      "Epoch 1, Step 490, Loss: 0.8442\n",
      "Epoch 1, Step 500, Loss: 0.9080\n",
      "Epoch 1, Step 510, Loss: 0.8360\n",
      "Epoch 1, Step 520, Loss: 0.8199\n",
      "Epoch 1, Step 530, Loss: 0.8274\n",
      "Epoch 1, Step 540, Loss: 0.8559\n",
      "Epoch 1, Step 550, Loss: 0.9088\n",
      "Epoch 1, Step 560, Loss: 0.8803\n",
      "Epoch 1, Step 570, Loss: 0.8038\n",
      "Epoch 1, Step 580, Loss: 0.8100\n",
      "Epoch 1, Step 590, Loss: 0.8762\n",
      "Epoch 1, Step 600, Loss: 0.8728\n",
      "Epoch 1, Step 610, Loss: 0.8118\n",
      "Epoch 1, Step 620, Loss: 0.8152\n",
      "Epoch 1, Step 630, Loss: 0.8091\n",
      "Epoch 1, Step 640, Loss: 0.8445\n",
      "Epoch 1, Step 650, Loss: 0.8039\n",
      "Epoch 1, Step 660, Loss: 0.8073\n",
      "Epoch 1, Step 670, Loss: 0.8225\n",
      "Epoch 1, Step 680, Loss: 0.7302\n",
      "Epoch 1, Step 690, Loss: 0.8050\n",
      "Epoch 1, Step 700, Loss: 0.8136\n",
      "Epoch 1, Step 710, Loss: 0.7692\n",
      "Epoch 1, Step 720, Loss: 0.8023\n",
      "Epoch 1, Step 730, Loss: 0.7458\n",
      "Epoch 1, Step 740, Loss: 0.8119\n",
      "Epoch 1, Step 750, Loss: 0.8042\n",
      "Epoch 1, Step 760, Loss: 0.8147\n",
      "Epoch 1, Step 770, Loss: 0.8041\n",
      "Epoch 1, Step 780, Loss: 0.8038\n",
      "Epoch 1, Step 790, Loss: 0.8114\n",
      "Epoch 1, Step 800, Loss: 0.8052\n",
      "Epoch 1, Step 810, Loss: 0.8871\n",
      "Epoch 1, Step 820, Loss: 0.8025\n",
      "Epoch 1, Step 830, Loss: 0.7733\n",
      "Epoch 1, Step 840, Loss: 0.7242\n",
      "Epoch 1, Step 850, Loss: 0.8153\n",
      "Epoch 1, Step 860, Loss: 0.7363\n",
      "Epoch 1, Step 870, Loss: 0.8151\n",
      "Epoch 1, Step 880, Loss: 0.8188\n",
      "Epoch 1, Step 890, Loss: 0.8541\n",
      "Epoch 1, Step 900, Loss: 0.8044\n",
      "Epoch 1, Step 910, Loss: 0.8048\n",
      "Epoch 1, Step 920, Loss: 0.8000\n",
      "Epoch 1, Step 930, Loss: 0.8891\n",
      "Epoch 1, Step 940, Loss: 0.8332\n",
      "Epoch 1, Step 950, Loss: 0.8005\n",
      "Epoch 1, Step 960, Loss: 0.7741\n",
      "Epoch 1, Step 970, Loss: 0.8335\n",
      "Epoch 1, Step 980, Loss: 0.8055\n",
      "Epoch 1, Step 990, Loss: 0.7164\n",
      "Epoch 1, Step 1000, Loss: 0.7844\n",
      "Epoch 1, Step 1010, Loss: 0.8061\n",
      "Epoch 1, Step 1020, Loss: 0.8041\n",
      "Epoch 1, Step 1030, Loss: 0.8007\n",
      "Epoch 1, Step 1040, Loss: 0.8008\n",
      "Epoch 1, Step 1050, Loss: 0.8006\n",
      "Epoch 1, Step 1060, Loss: 0.7994\n",
      "Epoch 1, Step 1070, Loss: 0.7769\n",
      "Epoch 1, Step 1080, Loss: 0.9460\n",
      "Epoch 1, Step 1090, Loss: 0.8034\n",
      "Epoch 1, Step 1100, Loss: 0.8182\n",
      "Epoch 1, Step 1110, Loss: 0.8020\n",
      "Epoch 1, Step 1120, Loss: 0.7818\n",
      "Epoch 1, Step 1130, Loss: 0.7993\n",
      "Epoch 1, Step 1140, Loss: 0.8180\n",
      "Epoch 1, Step 1150, Loss: 0.7998\n",
      "Epoch 1, Step 1160, Loss: 0.8010\n",
      "Epoch 1, Step 1170, Loss: 0.8004\n",
      "Epoch 1, Step 1180, Loss: 0.8718\n",
      "Epoch 1, Step 1190, Loss: 0.6964\n",
      "Epoch 1, Step 1200, Loss: 0.8005\n",
      "Epoch 1, Step 1210, Loss: 0.9366\n",
      "Epoch 1, Step 1220, Loss: 0.8339\n",
      "Epoch 1, Step 1230, Loss: 0.7996\n",
      "Epoch 1, Step 1240, Loss: 0.8006\n",
      "Epoch 1, Step 1250, Loss: 0.7496\n",
      "Epoch 1, Step 1260, Loss: 0.8533\n",
      "Epoch 1, Step 1270, Loss: 0.8000\n",
      "Epoch 1, Step 1280, Loss: 0.7292\n",
      "Epoch 1, Step 1290, Loss: 0.7997\n",
      "Epoch 1, Step 1300, Loss: 0.8017\n",
      "Epoch 1, Step 1310, Loss: 0.8013\n",
      "Epoch 1, Step 1320, Loss: 0.8010\n",
      "Epoch 1, Step 1330, Loss: 0.8052\n",
      "Epoch 1, Step 1340, Loss: 0.8096\n",
      "Epoch 1, Step 1350, Loss: 0.8064\n",
      "Epoch 1, Step 1360, Loss: 0.8454\n",
      "Epoch 1, Step 1370, Loss: 0.7659\n",
      "Epoch 1, Step 1380, Loss: 0.8576\n",
      "Epoch 1, Step 1390, Loss: 0.5884\n",
      "Epoch 1, Step 1400, Loss: 0.7994\n",
      "Epoch 1, Step 1410, Loss: 0.8986\n",
      "Epoch 1, Step 1420, Loss: 0.8027\n",
      "Epoch 1, Step 1430, Loss: 0.8072\n",
      "Epoch 1, Step 1440, Loss: 0.8632\n",
      "Epoch 1, Step 1450, Loss: 0.8038\n",
      "Epoch 1, Step 1460, Loss: 0.8005\n",
      "Epoch 1, Step 1470, Loss: 0.8225\n",
      "Epoch 1, Step 1480, Loss: 0.8527\n",
      "Epoch 1, Step 1490, Loss: 0.8000\n",
      "Epoch 1, Step 1500, Loss: 0.8748\n",
      "Epoch 1, Step 1510, Loss: 0.7973\n",
      "Epoch 1, Step 1520, Loss: 0.8073\n",
      "Epoch 1, Step 1530, Loss: 0.7894\n",
      "Epoch 1, Step 1540, Loss: 0.8004\n",
      "Epoch 1, Step 1550, Loss: 0.8014\n",
      "Epoch 1, Step 1560, Loss: 0.7992\n",
      "Epoch 1, Step 1570, Loss: 0.7997\n",
      "Epoch 1, Step 1580, Loss: 0.8292\n",
      "Epoch 1, Step 1590, Loss: 0.7964\n",
      "Epoch 1, Step 1600, Loss: 0.8000\n",
      "Epoch 1, Step 1610, Loss: 0.8005\n",
      "Epoch 1, Step 1620, Loss: 0.7997\n",
      "Epoch 1, Step 1630, Loss: 0.8198\n",
      "Epoch 1, Step 1640, Loss: 0.7993\n",
      "Epoch 1, Step 1650, Loss: 0.7996\n",
      "Epoch 1, Step 1660, Loss: 0.7247\n",
      "Epoch 1, Step 1670, Loss: 0.7993\n",
      "Epoch 1, Step 1680, Loss: 0.8523\n",
      "Epoch 1, Step 1690, Loss: 0.7994\n",
      "Epoch 1, Step 1700, Loss: 0.7962\n",
      "Epoch 1, Step 1710, Loss: 0.7994\n",
      "Epoch 1, Step 1720, Loss: 0.8032\n",
      "Epoch 1, Step 1730, Loss: 0.7004\n",
      "Epoch 1, Step 1740, Loss: 0.8001\n",
      "Epoch 1, Step 1750, Loss: 0.8007\n",
      "Epoch 1, Step 1760, Loss: 0.7949\n",
      "Epoch 1, Step 1770, Loss: 0.7995\n",
      "Epoch 1, Step 1780, Loss: 0.7997\n",
      "Epoch 1, Step 1790, Loss: 0.7991\n",
      "Epoch 1, Step 1800, Loss: 0.8005\n",
      "Epoch 1, Step 1810, Loss: 0.7992\n",
      "Epoch 1, Step 1820, Loss: 0.7150\n",
      "Epoch 1, Step 1830, Loss: 0.8006\n",
      "Epoch 1, Step 1840, Loss: 0.8026\n",
      "Epoch 1, Step 1850, Loss: 0.8020\n",
      "Epoch 1, Step 1860, Loss: 0.8006\n",
      "Epoch 1, Step 1870, Loss: 0.8077\n",
      "Epoch 1, Step 1880, Loss: 0.7706\n",
      "Epoch 1, Step 1890, Loss: 0.8008\n",
      "Epoch 1, Step 1900, Loss: 0.7711\n",
      "Epoch 1, Step 1910, Loss: 0.7991\n",
      "Epoch 1, Step 1920, Loss: 0.8006\n",
      "Epoch 1, Step 1930, Loss: 0.8005\n",
      "Epoch 1, Step 1940, Loss: 1.1303\n",
      "Epoch 1, Step 1950, Loss: 0.8000\n",
      "Epoch 1, Step 1960, Loss: 0.8168\n",
      "Epoch 1, Step 1970, Loss: 0.8761\n",
      "Epoch 1, Step 1980, Loss: 0.7991\n",
      "Epoch 1, Step 1990, Loss: 0.7990\n",
      "Epoch 1, Step 2000, Loss: 0.8011\n",
      "Epoch 1, Step 2010, Loss: 0.8016\n",
      "Epoch 1, Step 2020, Loss: 0.7800\n",
      "Epoch 1, Step 2030, Loss: 0.8050\n",
      "Epoch 1, Step 2040, Loss: 0.8346\n",
      "Epoch 1, Step 2050, Loss: 0.7996\n",
      "Epoch 1, Step 2060, Loss: 0.8011\n",
      "Epoch 1, Step 2070, Loss: 0.7806\n",
      "Epoch 1, Step 2080, Loss: 0.6625\n",
      "Epoch 1, Step 2090, Loss: 0.9130\n",
      "Epoch 1, Step 2100, Loss: 0.6115\n",
      "Epoch 1, Step 2110, Loss: 0.8004\n",
      "Epoch 1, Step 2120, Loss: 0.8019\n",
      "Epoch 1, Step 2130, Loss: 0.8046\n",
      "Epoch 1, Step 2140, Loss: 0.8022\n",
      "Epoch 1, Step 2150, Loss: 0.8184\n",
      "Epoch 1, Step 2160, Loss: 0.8011\n",
      "Epoch 1, Step 2170, Loss: 1.0634\n",
      "Epoch 1, Step 2180, Loss: 0.7997\n",
      "Epoch 1, Step 2190, Loss: 0.7990\n",
      "Epoch 1, Step 2200, Loss: 0.7996\n",
      "Epoch 1, Step 2210, Loss: 0.8001\n",
      "Epoch 1, Step 2220, Loss: 0.6768\n",
      "Epoch 1, Step 2230, Loss: 0.7497\n",
      "Epoch 1, Step 2240, Loss: 0.8000\n",
      "Epoch 1, Step 2250, Loss: 0.6744\n",
      "Epoch 1, Step 2260, Loss: 0.8042\n",
      "Epoch 1, Step 2270, Loss: 0.8032\n",
      "Epoch 1, Step 2280, Loss: 0.8860\n",
      "Epoch 1, Step 2290, Loss: 0.8446\n",
      "Epoch 1, Step 2300, Loss: 1.0017\n",
      "Epoch 1, Step 2310, Loss: 0.8002\n",
      "Epoch 1, Step 2320, Loss: 0.9517\n",
      "Epoch 1, Step 2330, Loss: 0.7988\n",
      "Epoch 1, Step 2340, Loss: 0.8001\n",
      "Epoch 1, Step 2350, Loss: 0.8003\n",
      "Epoch 1, Step 2360, Loss: 0.7688\n",
      "Epoch 1, Step 2370, Loss: 0.8215\n",
      "Epoch 1, Step 2380, Loss: 0.8010\n",
      "Epoch 1, Step 2390, Loss: 0.7989\n",
      "Epoch 1, Step 2400, Loss: 0.7810\n",
      "Epoch 1, Step 2410, Loss: 0.7992\n",
      "Epoch 1, Step 2420, Loss: 0.8079\n",
      "Epoch 1, Step 2430, Loss: 0.8017\n",
      "Epoch 1, Step 2440, Loss: 0.8007\n",
      "Epoch 1, Step 2450, Loss: 0.7996\n",
      "Epoch 1, Step 2460, Loss: 0.7198\n",
      "Epoch 1, Step 2470, Loss: 0.8999\n",
      "Epoch 1, Step 2480, Loss: 0.8191\n",
      "Epoch 1, Step 2490, Loss: 1.1341\n",
      "Epoch 1, Step 2500, Loss: 0.7990\n",
      "Epoch 1, Step 2510, Loss: 0.7988\n",
      "Epoch 1, Step 2520, Loss: 0.7679\n",
      "Epoch 1, Step 2530, Loss: 0.8693\n",
      "Epoch 1, Step 2540, Loss: 0.8003\n",
      "Epoch 1, Step 2550, Loss: 0.8010\n",
      "Epoch 1, Step 2560, Loss: 0.8102\n",
      "Epoch 1, Step 2570, Loss: 0.8015\n",
      "Epoch 1, Step 2580, Loss: 0.7997\n",
      "Epoch 1, Step 2590, Loss: 0.7773\n",
      "Epoch 1, Step 2600, Loss: 0.7992\n",
      "Epoch 1, Step 2610, Loss: 0.7989\n",
      "Epoch 1, Step 2620, Loss: 0.8197\n",
      "Epoch 1, Step 2630, Loss: 0.8132\n",
      "Epoch 1, Step 2640, Loss: 0.7993\n",
      "Epoch 1, Step 2650, Loss: 0.8166\n",
      "Epoch 1, Step 2660, Loss: 0.7266\n",
      "Epoch 1, Step 2670, Loss: 0.7996\n",
      "Epoch 1, Step 2680, Loss: 0.7996\n",
      "Epoch 1, Step 2690, Loss: 0.8934\n",
      "Epoch 1, Step 2700, Loss: 0.7892\n",
      "Epoch 1, Step 2710, Loss: 0.7996\n",
      "Epoch 1, Step 2720, Loss: 0.8024\n",
      "Epoch 1, Step 2730, Loss: 0.7998\n",
      "Epoch 1, Step 2740, Loss: 0.7991\n",
      "Epoch 1, Step 2750, Loss: 0.7992\n",
      "Epoch 1, Step 2760, Loss: 0.7390\n",
      "Epoch 1, Step 2770, Loss: 0.8040\n",
      "Epoch 1, Step 2780, Loss: 0.7999\n",
      "Epoch 1, Step 2790, Loss: 0.7997\n",
      "Epoch 1, Step 2800, Loss: 0.7994\n",
      "Epoch 1, Step 2810, Loss: 0.8048\n",
      "Epoch 1, Step 2820, Loss: 0.7989\n",
      "Epoch 1, Step 2830, Loss: 0.7993\n",
      "Epoch 1, Step 2840, Loss: 0.7744\n",
      "Epoch 1, Step 2850, Loss: 0.7726\n",
      "Epoch 1, Step 2860, Loss: 0.8001\n",
      "Epoch 1, Step 2870, Loss: 0.7995\n",
      "Epoch 1, Step 2880, Loss: 0.7994\n",
      "Epoch 1, Step 2890, Loss: 0.7879\n",
      "Epoch 1, Step 2900, Loss: 0.8006\n",
      "Epoch 1, Step 2910, Loss: 0.7990\n",
      "Epoch 1, Step 2920, Loss: 0.7683\n",
      "Epoch 1, Step 2930, Loss: 0.8006\n",
      "Epoch 1, Step 2940, Loss: 0.7337\n",
      "Epoch 1, Step 2950, Loss: 0.8002\n",
      "Epoch 1, Step 2960, Loss: 0.7728\n",
      "Epoch 1, Step 2970, Loss: 0.8009\n",
      "Epoch 1, Step 2980, Loss: 0.7994\n",
      "Epoch 1, Step 2990, Loss: 0.8007\n",
      "Epoch 1, Step 3000, Loss: 0.7989\n",
      "Epoch 1, Step 3010, Loss: 0.8013\n",
      "Epoch 1, Step 3020, Loss: 0.7995\n",
      "Epoch 1, Step 3030, Loss: 0.8005\n",
      "Epoch 1, Step 3040, Loss: 0.7998\n",
      "Epoch 1, Step 3050, Loss: 0.8008\n",
      "Epoch 1, Step 3060, Loss: 0.7820\n",
      "Epoch 1, Step 3070, Loss: 0.7562\n",
      "Epoch 1, Step 3080, Loss: 0.7999\n",
      "Epoch 1, Step 3090, Loss: 0.7991\n",
      "Epoch 1, Step 3100, Loss: 0.8011\n",
      "Epoch 1, Step 3110, Loss: 0.7996\n",
      "Epoch 1, Step 3120, Loss: 0.7996\n",
      "Epoch 1, Step 3130, Loss: 0.7994\n",
      "Epoch 1, Step 3140, Loss: 0.8810\n",
      "Epoch 1, Step 3150, Loss: 0.8793\n",
      "Epoch 1, Step 3160, Loss: 0.7991\n",
      "Epoch 1, Step 3170, Loss: 0.7996\n",
      "Epoch 1, Step 3180, Loss: 0.7994\n",
      "Epoch 1, Step 3190, Loss: 0.7735\n",
      "Epoch 1, Step 3200, Loss: 0.8017\n",
      "Epoch 1, Step 3210, Loss: 0.8000\n",
      "Epoch 1, Step 3220, Loss: 0.7896\n",
      "Epoch 1, Step 3230, Loss: 0.8010\n",
      "Epoch 1, Step 3240, Loss: 0.7637\n",
      "Epoch 1, Step 3250, Loss: 0.7986\n",
      "Epoch 1, Step 3260, Loss: 0.7785\n",
      "Epoch 1, Step 3270, Loss: 0.8242\n",
      "Epoch 1, Step 3280, Loss: 1.1577\n",
      "Epoch 1, Step 3290, Loss: 0.7975\n",
      "Epoch 1, Step 3300, Loss: 0.8144\n",
      "Epoch 1, Step 3310, Loss: 0.8070\n",
      "Epoch 1, Step 3320, Loss: 0.8155\n",
      "Epoch 1, Step 3330, Loss: 0.8002\n",
      "Epoch 1, Step 3340, Loss: 0.7961\n",
      "Epoch 1, Step 3350, Loss: 0.8565\n",
      "Epoch 1, Step 3360, Loss: 0.7997\n",
      "Epoch 1, Step 3370, Loss: 0.8028\n",
      "Epoch 1, Step 3380, Loss: 0.8027\n",
      "Epoch 1, Step 3390, Loss: 0.8022\n",
      "Epoch 1, Step 3400, Loss: 0.8712\n",
      "Epoch 1, Step 3410, Loss: 0.8049\n",
      "Epoch 1, Step 3420, Loss: 0.6421\n",
      "Epoch 1, Step 3430, Loss: 0.8017\n",
      "Epoch 1, Step 3440, Loss: 0.7993\n",
      "Epoch 1, Step 3450, Loss: 0.7493\n",
      "Epoch 1, Step 3460, Loss: 0.8058\n",
      "Epoch 1, Step 3470, Loss: 1.2918\n",
      "Epoch 1, Step 3480, Loss: 0.8065\n",
      "Epoch 1, Step 3490, Loss: 0.7086\n",
      "Epoch 1, Step 3500, Loss: 0.7591\n",
      "Epoch 1, Step 3510, Loss: 0.7203\n",
      "Epoch 1, Step 3520, Loss: 0.7996\n",
      "Epoch 1, Step 3530, Loss: 0.7995\n",
      "Epoch 1, Step 3540, Loss: 0.7435\n",
      "Epoch 1, Step 3550, Loss: 0.7660\n",
      "Epoch 1, Step 3560, Loss: 0.7975\n",
      "Epoch 1, Step 3570, Loss: 0.7960\n",
      "Epoch 1, Step 3580, Loss: 0.7992\n",
      "Epoch 1, Step 3590, Loss: 0.8540\n",
      "Epoch 1, Step 3600, Loss: 0.7885\n",
      "Epoch 1, Step 3610, Loss: 0.8382\n",
      "Epoch 1, Step 3620, Loss: 0.8031\n",
      "Epoch 1, Step 3630, Loss: 0.7991\n",
      "Epoch 1, Step 3640, Loss: 0.7993\n",
      "Epoch 1, Step 3650, Loss: 0.8159\n",
      "Epoch 1, Step 3660, Loss: 0.8111\n",
      "Epoch 1, Step 3670, Loss: 0.8167\n",
      "Epoch 1, Step 3680, Loss: 0.6452\n",
      "Epoch 1, Step 3690, Loss: 0.8454\n",
      "Epoch 1, Step 3700, Loss: 0.8100\n",
      "Epoch 1, Step 3710, Loss: 0.5309\n",
      "Epoch 1, Step 3720, Loss: 0.7507\n",
      "Epoch 1, Step 3730, Loss: 0.8170\n",
      "Epoch 1, Step 3740, Loss: 0.7954\n",
      "Epoch 1, Step 3750, Loss: 0.6923\n",
      "Epoch 1, Step 3760, Loss: 0.8100\n",
      "Epoch 1, Step 3770, Loss: 0.6483\n",
      "Epoch 1, Step 3780, Loss: 0.7781\n",
      "Epoch 1, Step 3790, Loss: 0.6268\n",
      "Epoch 1, Step 3800, Loss: 0.8337\n",
      "Epoch 1, Step 3810, Loss: 0.5176\n",
      "Epoch 1, Step 3820, Loss: 0.8061\n",
      "Epoch 1, Step 3830, Loss: 0.8250\n",
      "Epoch 1, Step 3840, Loss: 0.8095\n",
      "Epoch 1, Step 3850, Loss: 0.8010\n",
      "Epoch 1, Step 3860, Loss: 0.6954\n",
      "Epoch 1, Step 3870, Loss: 0.7995\n",
      "Epoch 1, Step 3880, Loss: 0.8957\n",
      "Epoch 1, Step 3890, Loss: 0.7991\n",
      "Epoch 1, Step 3900, Loss: 0.7987\n",
      "Epoch 1, Step 3910, Loss: 0.7945\n",
      "Epoch 1, Step 3920, Loss: 0.8007\n",
      "Epoch 1, Step 3930, Loss: 0.8402\n",
      "Epoch 1, Step 3940, Loss: 0.7987\n",
      "Epoch 1, Step 3950, Loss: 0.8260\n",
      "Epoch 1, Step 3960, Loss: 0.7987\n",
      "Epoch 1, Step 3970, Loss: 0.8341\n",
      "Epoch 1, Step 3980, Loss: 0.8211\n",
      "Epoch 1, Step 3990, Loss: 0.8004\n",
      "Epoch 1, Step 4000, Loss: 0.8188\n",
      "Epoch 1, Step 4010, Loss: 0.8331\n",
      "Epoch 1, Step 4020, Loss: 0.7925\n",
      "Epoch 1, Step 4030, Loss: 0.8392\n",
      "Epoch 1, Step 4040, Loss: 0.7322\n",
      "Epoch 1, Step 4050, Loss: 0.7448\n",
      "Epoch 1, Step 4060, Loss: 0.8112\n",
      "Epoch 1, Step 4070, Loss: 0.9770\n",
      "Epoch 1, Step 4080, Loss: 0.7978\n",
      "Epoch 1, Step 4090, Loss: 0.7996\n",
      "Epoch 1, Step 4100, Loss: 0.7992\n",
      "Epoch 1, Step 4110, Loss: 0.7987\n",
      "Epoch 1, Step 4120, Loss: 0.7850\n",
      "Epoch 1, Step 4130, Loss: 0.9098\n",
      "Epoch 1, Step 4140, Loss: 0.7990\n",
      "Epoch 1, Step 4150, Loss: 0.7805\n",
      "Epoch 1, Step 4160, Loss: 0.7576\n",
      "Epoch 1, Step 4170, Loss: 0.6475\n",
      "Epoch 1, Step 4180, Loss: 0.8245\n",
      "Epoch 1, Step 4190, Loss: 0.8037\n",
      "Epoch 1, Step 4200, Loss: 0.8002\n",
      "Epoch 1, Step 4210, Loss: 0.7992\n",
      "Epoch 1, Step 4220, Loss: 0.7990\n",
      "Epoch 1, Step 4230, Loss: 0.6560\n",
      "Epoch 1, Step 4240, Loss: 0.7991\n",
      "Epoch 1, Step 4250, Loss: 0.7603\n",
      "Epoch 1, Step 4260, Loss: 0.8340\n",
      "Epoch 1, Step 4270, Loss: 0.7991\n",
      "Epoch 1, Step 4280, Loss: 0.8003\n",
      "Epoch 1, Step 4290, Loss: 0.7990\n",
      "Epoch 1, Step 4300, Loss: 0.7991\n",
      "Epoch 1, Step 4310, Loss: 0.8008\n",
      "Epoch 1, Step 4320, Loss: 0.8010\n",
      "Epoch 1, Step 4330, Loss: 0.7992\n",
      "Epoch 1, Step 4340, Loss: 0.7986\n",
      "Epoch 1, Step 4350, Loss: 0.6424\n",
      "Epoch 1, Step 4360, Loss: 0.7996\n",
      "Epoch 1, Step 4370, Loss: 0.7992\n",
      "Epoch 1, Step 4380, Loss: 0.7991\n",
      "Epoch 1, Step 4390, Loss: 0.7277\n",
      "Epoch 1, Step 4400, Loss: 0.7989\n",
      "Epoch 1, Step 4410, Loss: 0.7028\n",
      "Epoch 1, Step 4420, Loss: 0.8001\n",
      "Epoch 1, Step 4430, Loss: 0.8162\n",
      "Epoch 1, Step 4440, Loss: 0.8065\n",
      "Epoch 1, Step 4450, Loss: 0.7181\n",
      "Epoch 1, Step 4460, Loss: 0.8156\n",
      "Epoch 1, Step 4470, Loss: 0.8130\n",
      "Epoch 1, Step 4480, Loss: 0.8109\n",
      "Epoch 1, Step 4490, Loss: 0.8002\n",
      "Epoch 1, Step 4500, Loss: 1.0537\n",
      "Epoch 1, Step 4510, Loss: 1.3113\n",
      "Epoch 1, Step 4520, Loss: 0.8020\n",
      "Epoch 1, Step 4530, Loss: 0.8098\n",
      "Epoch 1, Step 4540, Loss: 0.7920\n",
      "Epoch 1, Step 4550, Loss: 0.7990\n",
      "Epoch 1, Step 4560, Loss: 0.7993\n",
      "Epoch 1, Step 4570, Loss: 0.8009\n",
      "Epoch 1, Step 4580, Loss: 0.7992\n",
      "Epoch 1, Step 4590, Loss: 0.7994\n",
      "Epoch 1, Step 4600, Loss: 0.8217\n",
      "Epoch 1, Step 4610, Loss: 0.8001\n",
      "Epoch 1, Step 4620, Loss: 0.6802\n",
      "Epoch 1, Step 4630, Loss: 0.8005\n",
      "Epoch 1, Step 4640, Loss: 0.6772\n",
      "Epoch 1, Step 4650, Loss: 0.7992\n",
      "Epoch 1, Step 4660, Loss: 0.7989\n",
      "Epoch 1, Step 4670, Loss: 0.8003\n",
      "Epoch 1, Step 4680, Loss: 0.8034\n",
      "Epoch 1, Step 4690, Loss: 0.7524\n",
      "Epoch 1, Step 4700, Loss: 0.7492\n",
      "Epoch 1, Step 4710, Loss: 0.8013\n",
      "Epoch 1, Step 4720, Loss: 0.8247\n",
      "Epoch 1, Step 4730, Loss: 0.8870\n",
      "Epoch 1, Step 4740, Loss: 0.7891\n",
      "Epoch 1, Step 4750, Loss: 0.7989\n",
      "Epoch 1, Step 4760, Loss: 0.7116\n",
      "Epoch 1, Step 4770, Loss: 0.8302\n",
      "Epoch 1, Step 4780, Loss: 0.7995\n",
      "Epoch 1, Step 4790, Loss: 1.1536\n",
      "Epoch 1, Step 4800, Loss: 0.8003\n",
      "Epoch 1, Step 4810, Loss: 0.8030\n",
      "Epoch 1, Step 4820, Loss: 0.8010\n",
      "Epoch 1, Step 4830, Loss: 0.5939\n",
      "Epoch 1, Step 4840, Loss: 0.7781\n",
      "Epoch 1, Step 4850, Loss: 0.7994\n",
      "Epoch 1, Step 4860, Loss: 0.8004\n",
      "Epoch 1, Step 4870, Loss: 0.7991\n",
      "Epoch 1, Step 4880, Loss: 0.7986\n",
      "Epoch 1, Step 4890, Loss: 0.8004\n",
      "Epoch 1, Step 4900, Loss: 0.7989\n",
      "Epoch 1, Step 4910, Loss: 0.8003\n",
      "Epoch 1, Step 4920, Loss: 0.8067\n",
      "Epoch 1, Step 4930, Loss: 0.8088\n",
      "Epoch 1, Step 4940, Loss: 0.8000\n",
      "Epoch 1, Step 4950, Loss: 0.7998\n",
      "Epoch 1, Step 4960, Loss: 0.7994\n",
      "Epoch 1, Step 4970, Loss: 1.1047\n",
      "Epoch 1, Step 4980, Loss: 0.8268\n",
      "Epoch 1, Step 4990, Loss: 0.8016\n",
      "Epoch 1, Step 5000, Loss: 0.8106\n",
      "Epoch 1, Step 5010, Loss: 0.7994\n",
      "Epoch 1, Step 5020, Loss: 0.8904\n",
      "Epoch 1, Step 5030, Loss: 0.8371\n",
      "Epoch 1, Step 5040, Loss: 0.8682\n",
      "Epoch 1, Step 5050, Loss: 0.8028\n",
      "Epoch 1, Step 5060, Loss: 0.8000\n",
      "Epoch 1, Step 5070, Loss: 0.7988\n",
      "Epoch 1, Step 5080, Loss: 0.8830\n",
      "Epoch 1, Step 5090, Loss: 0.7002\n",
      "Epoch 1, Step 5100, Loss: 0.7999\n",
      "Epoch 1, Step 5110, Loss: 0.7997\n",
      "Epoch 1, Step 5120, Loss: 0.8008\n",
      "Epoch 1, Step 5130, Loss: 0.7732\n",
      "Epoch 1, Step 5140, Loss: 0.8030\n",
      "Epoch 1, Step 5150, Loss: 0.7995\n",
      "Epoch 1, Step 5160, Loss: 0.7997\n",
      "Epoch 1, Step 5170, Loss: 0.7991\n",
      "Epoch 1, Step 5180, Loss: 0.7941\n",
      "Epoch 1, Step 5190, Loss: 0.8086\n",
      "Epoch 1, Step 5200, Loss: 0.7993\n",
      "Epoch 1, Step 5210, Loss: 0.7995\n",
      "Epoch 1, Step 5220, Loss: 0.8148\n",
      "Epoch 1, Step 5230, Loss: 0.7994\n",
      "Epoch 1, Step 5240, Loss: 0.8003\n",
      "Epoch 1, Step 5250, Loss: 0.8002\n",
      "Epoch 1, Step 5260, Loss: 0.8029\n",
      "Epoch 1, Step 5270, Loss: 0.7843\n",
      "Epoch 1, Step 5280, Loss: 0.7676\n",
      "Epoch 1, Step 5290, Loss: 0.6894\n",
      "Epoch 1, Step 5300, Loss: 0.9814\n",
      "Epoch 1, Step 5310, Loss: 0.7234\n",
      "Epoch 1, Step 5320, Loss: 0.8045\n",
      "Epoch 1, Step 5330, Loss: 0.8220\n",
      "Epoch 1, Step 5340, Loss: 0.7997\n",
      "Epoch 1, Step 5350, Loss: 0.8000\n",
      "Epoch 1, Step 5360, Loss: 0.7988\n",
      "Epoch 1, Step 5370, Loss: 0.7679\n",
      "Epoch 1, Step 5380, Loss: 0.7989\n",
      "Epoch 1, Step 5390, Loss: 0.8174\n",
      "Epoch 1, Step 5400, Loss: 0.7993\n",
      "Epoch 1, Step 5410, Loss: 0.8006\n",
      "Epoch 1, Step 5420, Loss: 0.6787\n",
      "Epoch 1, Step 5430, Loss: 0.7992\n",
      "Epoch 1, Step 5440, Loss: 0.5514\n",
      "Epoch 1, Step 5450, Loss: 0.7619\n",
      "Epoch 1, Step 5460, Loss: 0.8204\n",
      "Epoch 1, Step 5470, Loss: 1.0017\n",
      "Epoch 1, Step 5480, Loss: 0.7993\n",
      "Epoch 1, Step 5490, Loss: 0.9178\n",
      "Epoch 1, Step 5500, Loss: 0.7995\n",
      "Epoch 1, Step 5510, Loss: 0.7752\n",
      "Epoch 1, Step 5520, Loss: 0.7989\n",
      "Epoch 1, Step 5530, Loss: 0.8015\n",
      "Epoch 1, Step 5540, Loss: 0.7990\n",
      "Epoch 1, Step 5550, Loss: 0.6826\n",
      "Epoch 1, Step 5560, Loss: 0.7789\n",
      "Epoch 1, Step 5570, Loss: 0.7993\n",
      "Epoch 1, Step 5580, Loss: 0.7991\n",
      "Epoch 1, Step 5590, Loss: 0.7992\n",
      "Epoch 1, Step 5600, Loss: 0.8150\n",
      "Epoch 1, Step 5610, Loss: 0.8467\n",
      "Epoch 1, Step 5620, Loss: 0.8059\n",
      "Epoch 1, Step 5630, Loss: 0.7993\n",
      "Epoch 1, Step 5640, Loss: 0.7556\n",
      "Epoch 1, Step 5650, Loss: 0.7836\n",
      "Epoch 1, Step 5660, Loss: 0.8509\n",
      "Epoch 1, Step 5670, Loss: 0.8093\n",
      "Epoch 1, Step 5680, Loss: 0.7990\n",
      "Epoch 1, Step 5690, Loss: 0.7703\n",
      "Epoch 1, Step 5700, Loss: 0.8316\n",
      "Epoch 1, Step 5710, Loss: 0.7993\n",
      "Epoch 1, Step 5720, Loss: 0.7992\n",
      "Epoch 1, Step 5730, Loss: 0.7376\n",
      "Epoch 1, Step 5740, Loss: 0.7530\n",
      "Epoch 1, Step 5750, Loss: 0.7994\n",
      "Epoch 1, Step 5760, Loss: 0.7990\n",
      "Epoch 1, Step 5770, Loss: 0.7116\n",
      "Epoch 1, Step 5780, Loss: 0.7795\n",
      "Epoch 1, Step 5790, Loss: 0.8033\n",
      "Epoch 1, Step 5800, Loss: 0.7994\n",
      "Epoch 1, Step 5810, Loss: 0.7988\n",
      "Epoch 1, Step 5820, Loss: 0.7989\n",
      "Epoch 1, Step 5830, Loss: 0.7990\n",
      "Epoch 1, Step 5840, Loss: 0.7992\n",
      "Epoch 1, Step 5850, Loss: 0.7317\n",
      "Epoch 1, Step 5860, Loss: 0.7882\n",
      "Epoch 1, Step 5870, Loss: 0.7988\n",
      "Epoch 1, Step 5880, Loss: 0.7473\n",
      "Epoch 1, Step 5890, Loss: 0.7989\n",
      "Epoch 1, Step 5900, Loss: 0.7996\n",
      "Epoch 1, Step 5910, Loss: 0.7200\n",
      "Epoch 1, Step 5920, Loss: 0.7860\n",
      "Epoch 1, Step 5930, Loss: 0.8188\n",
      "Epoch 1, Step 5940, Loss: 0.8488\n",
      "Epoch 1, Step 5950, Loss: 0.8542\n",
      "Epoch 1, Step 5960, Loss: 0.8296\n",
      "Epoch 1, Step 5970, Loss: 0.7988\n",
      "Epoch 1, Step 5980, Loss: 0.7996\n",
      "Epoch 1, Step 5990, Loss: 0.7679\n",
      "Epoch 1, Step 6000, Loss: 0.7479\n",
      "Epoch 1, Step 6010, Loss: 0.7993\n",
      "Epoch 1, Step 6020, Loss: 0.8301\n",
      "Epoch 1, Step 6030, Loss: 0.7826\n",
      "Epoch 1, Step 6040, Loss: 0.7989\n",
      "Epoch 1, Step 6050, Loss: 0.7986\n",
      "Epoch 1, Step 6060, Loss: 0.7994\n",
      "Epoch 1, Step 6070, Loss: 0.8215\n",
      "Epoch 1, Step 6080, Loss: 0.7630\n",
      "Epoch 1, Step 6090, Loss: 0.7816\n",
      "Epoch 1, Step 6100, Loss: 0.7977\n",
      "Epoch 1, Step 6110, Loss: 0.8007\n",
      "Epoch 1, Step 6120, Loss: 0.7995\n",
      "Epoch 1, Step 6130, Loss: 0.7988\n",
      "Epoch 1, Step 6140, Loss: 0.7859\n",
      "Epoch 1, Step 6150, Loss: 0.7793\n",
      "Epoch 1, Step 6160, Loss: 0.7998\n",
      "Epoch 1, Step 6170, Loss: 0.7986\n",
      "Epoch 1, Step 6180, Loss: 0.7994\n",
      "Epoch 1, Step 6190, Loss: 0.8216\n",
      "Epoch 1, Step 6200, Loss: 0.7988\n",
      "Epoch 1, Step 6210, Loss: 0.7992\n",
      "Epoch 1, Step 6220, Loss: 0.7440\n",
      "Epoch 1, Step 6230, Loss: 0.7993\n",
      "Epoch 1, Step 6240, Loss: 0.7564\n",
      "Epoch 1, Step 6250, Loss: 0.7990\n",
      "Epoch 1, Step 6260, Loss: 0.7990\n",
      "Epoch 1, Step 6270, Loss: 0.7991\n",
      "Epoch 1, Step 6280, Loss: 0.8365\n",
      "Epoch 1, Step 6290, Loss: 0.7998\n",
      "Epoch 1, Step 6300, Loss: 0.7968\n",
      "Epoch 1, Step 6310, Loss: 0.7989\n",
      "Epoch 1, Step 6320, Loss: 0.7967\n",
      "Epoch 1, Step 6330, Loss: 0.7909\n",
      "Epoch 1, Step 6340, Loss: 0.6902\n",
      "Epoch 1, Step 6350, Loss: 0.7829\n",
      "Epoch 1, Step 6360, Loss: 0.8002\n",
      "Epoch 1, Step 6370, Loss: 0.9391\n",
      "Epoch 1, Step 6380, Loss: 0.7999\n",
      "Epoch 1, Step 6390, Loss: 0.8085\n",
      "Epoch 1, Step 6400, Loss: 0.8020\n",
      "Epoch 1, Step 6410, Loss: 0.8049\n",
      "Epoch 1, Step 6420, Loss: 0.5624\n",
      "Epoch 1, Step 6430, Loss: 0.7025\n",
      "Epoch 1, Step 6440, Loss: 0.7254\n",
      "Epoch 1, Step 6450, Loss: 0.7831\n",
      "Epoch 1, Step 6460, Loss: 0.8007\n",
      "Epoch 1, Step 6470, Loss: 0.7992\n",
      "Epoch 1, Step 6480, Loss: 0.8377\n",
      "Epoch 1, Step 6490, Loss: 0.8252\n",
      "Epoch 1, Step 6500, Loss: 0.7989\n",
      "Epoch 1, Step 6510, Loss: 0.7988\n",
      "Epoch 1, Step 6520, Loss: 0.7987\n",
      "Epoch 1, Step 6530, Loss: 0.7901\n",
      "Epoch 1, Step 6540, Loss: 0.8134\n",
      "Epoch 1, Step 6550, Loss: 0.8487\n",
      "Epoch 1, Step 6560, Loss: 0.7557\n",
      "Epoch 1, Step 6570, Loss: 0.7993\n",
      "Epoch 1, Step 6580, Loss: 0.7996\n",
      "Epoch 1, Step 6590, Loss: 0.8278\n",
      "Epoch 1, Step 6600, Loss: 0.7989\n",
      "Epoch 1, Step 6610, Loss: 0.7989\n",
      "Epoch 1, Step 6620, Loss: 0.7889\n",
      "Epoch 1, Step 6630, Loss: 0.7990\n",
      "Epoch 1, Step 6640, Loss: 0.7518\n",
      "Epoch 1, Step 6650, Loss: 0.6896\n",
      "Epoch 1, Step 6660, Loss: 0.7760\n",
      "Epoch 1, Step 6670, Loss: 0.6823\n",
      "Epoch 1, Step 6680, Loss: 0.8112\n",
      "Epoch 1, Step 6690, Loss: 0.8000\n",
      "Epoch 1, Step 6700, Loss: 0.7993\n",
      "Epoch 1, Step 6710, Loss: 0.8025\n",
      "Epoch 1, Step 6720, Loss: 0.8034\n",
      "Epoch 1, Step 6730, Loss: 0.7993\n",
      "Epoch 1, Step 6740, Loss: 0.9093\n",
      "Epoch 1, Step 6750, Loss: 0.7997\n",
      "Epoch 1, Step 6760, Loss: 0.8435\n",
      "Epoch 1, Step 6770, Loss: 0.7947\n",
      "Epoch 1, Step 6780, Loss: 1.3132\n",
      "Epoch 1, Step 6790, Loss: 0.8307\n",
      "Epoch 1, Step 6800, Loss: 0.8016\n",
      "Epoch 1, Step 6810, Loss: 0.7994\n",
      "Epoch 1, Step 6820, Loss: 0.7973\n",
      "Epoch 1, Step 6830, Loss: 0.7984\n",
      "Epoch 1, Step 6840, Loss: 0.8031\n",
      "Epoch 1, Step 6850, Loss: 0.7989\n",
      "Epoch 1, Step 6860, Loss: 0.8176\n",
      "Epoch 1, Step 6870, Loss: 0.7970\n",
      "Epoch 1, Step 6880, Loss: 0.7997\n",
      "Epoch 1, Step 6890, Loss: 0.8007\n",
      "Epoch 1, Step 6900, Loss: 0.7991\n",
      "Epoch 1, Step 6910, Loss: 0.4819\n",
      "Epoch 1, Step 6920, Loss: 0.6605\n",
      "Epoch 1, Step 6930, Loss: 0.7989\n",
      "Epoch 1, Step 6940, Loss: 0.8152\n",
      "Epoch 1, Step 6950, Loss: 0.9554\n",
      "Epoch 1, Step 6960, Loss: 0.7996\n",
      "Epoch 1, Step 6970, Loss: 0.8025\n",
      "Epoch 1, Step 6980, Loss: 0.7724\n",
      "Epoch 1, Step 6990, Loss: 0.6014\n",
      "Epoch 1, Step 7000, Loss: 0.8101\n",
      "Epoch 1, Step 7010, Loss: 0.8741\n",
      "Epoch 1, Step 7020, Loss: 0.7243\n",
      "Epoch 1, Step 7030, Loss: 0.7996\n",
      "Epoch 1, Step 7040, Loss: 0.7570\n",
      "Epoch 1, Step 7050, Loss: 0.4978\n",
      "Epoch 1, Step 7060, Loss: 0.8704\n",
      "Epoch 1, Step 7070, Loss: 0.8103\n",
      "Epoch 1, Step 7080, Loss: 0.7857\n",
      "Epoch 1, Step 7090, Loss: 0.6832\n",
      "Epoch 1, Step 7100, Loss: 0.8007\n",
      "Epoch 1, Step 7110, Loss: 0.7278\n",
      "Epoch 1, Step 7120, Loss: 0.6619\n",
      "Epoch 1, Step 7130, Loss: 0.8046\n",
      "Epoch 1, Step 7140, Loss: 0.9881\n",
      "Epoch 1, Step 7150, Loss: 0.7200\n",
      "Epoch 1, Step 7160, Loss: 0.6195\n",
      "Epoch 1, Step 7170, Loss: 0.7993\n",
      "Epoch 1, Step 7180, Loss: 0.8685\n",
      "Epoch 1, Step 7190, Loss: 1.1460\n",
      "Epoch 1, Step 7200, Loss: 0.8015\n",
      "Epoch 1, Step 7210, Loss: 0.7996\n",
      "Epoch 1, Step 7220, Loss: 0.7990\n",
      "Epoch 1, Step 7230, Loss: 0.7328\n",
      "Epoch 1, Step 7240, Loss: 0.8860\n",
      "Epoch 1, Step 7250, Loss: 0.8010\n",
      "Epoch 1, Step 7260, Loss: 0.7507\n",
      "Epoch 1, Step 7270, Loss: 0.7575\n",
      "Epoch 1, Step 7280, Loss: 0.7643\n",
      "Epoch 1, Step 7290, Loss: 0.8008\n",
      "Epoch 1, Step 7300, Loss: 0.8307\n",
      "Epoch 1, Step 7310, Loss: 0.8009\n",
      "Epoch 1, Step 7320, Loss: 0.7889\n",
      "Epoch 1, Step 7330, Loss: 0.8156\n",
      "Epoch 1, Step 7340, Loss: 0.6901\n",
      "Epoch 1, Step 7350, Loss: 0.7990\n",
      "Epoch 1, Step 7360, Loss: 0.7999\n",
      "Epoch 1, Step 7370, Loss: 0.7993\n",
      "Epoch 1, Step 7380, Loss: 0.7992\n",
      "Epoch 1, Step 7390, Loss: 0.7998\n",
      "Epoch 1, Step 7400, Loss: 0.8153\n",
      "Epoch 1, Step 7410, Loss: 0.7943\n",
      "Epoch 1, Step 7420, Loss: 0.7935\n",
      "Epoch 1, Step 7430, Loss: 0.8086\n",
      "Epoch 1, Step 7440, Loss: 0.7996\n",
      "Epoch 1, Step 7450, Loss: 0.8019\n",
      "Epoch 1, Step 7460, Loss: 0.7746\n",
      "Epoch 1, Step 7470, Loss: 0.8013\n",
      "Epoch 1, Step 7480, Loss: 0.7988\n",
      "Epoch 1, Step 7490, Loss: 0.8053\n",
      "Epoch 1, Step 7500, Loss: 0.7476\n",
      "Epoch 1, Step 7510, Loss: 0.7311\n",
      "Epoch 1, Step 7520, Loss: 0.9185\n",
      "Epoch 1, Step 7530, Loss: 0.8012\n",
      "Epoch 1, Step 7540, Loss: 0.8358\n",
      "Epoch 1, Step 7550, Loss: 0.8033\n",
      "Epoch 1, Step 7560, Loss: 0.7755\n",
      "Epoch 1, Step 7570, Loss: 0.7748\n",
      "Epoch 1, Step 7580, Loss: 0.7097\n",
      "Epoch 1, Step 7590, Loss: 0.7423\n",
      "Epoch 1, Step 7600, Loss: 0.8687\n",
      "Epoch 1, Step 7610, Loss: 0.8110\n",
      "Epoch 1, Step 7620, Loss: 0.7476\n",
      "Epoch 1, Step 7630, Loss: 0.8862\n",
      "Epoch 1, Step 7640, Loss: 0.8005\n",
      "Epoch 1, Step 7650, Loss: 0.8100\n",
      "Epoch 1, Step 7660, Loss: 0.7039\n",
      "Epoch 1, Step 7670, Loss: 0.8068\n",
      "Epoch 1, Step 7680, Loss: 0.8069\n",
      "Epoch 1, Step 7690, Loss: 0.8341\n",
      "Epoch 1, Step 7700, Loss: 0.7609\n",
      "Epoch 1, Step 7710, Loss: 0.7999\n",
      "Epoch 1, Step 7720, Loss: 0.4041\n",
      "Epoch 1, Step 7730, Loss: 0.8052\n",
      "Epoch 1, Step 7740, Loss: 0.8035\n",
      "Epoch 1, Step 7750, Loss: 0.7998\n",
      "Epoch 1, Step 7760, Loss: 0.8154\n",
      "Epoch 1, Step 7770, Loss: 0.8005\n",
      "Epoch 1, Step 7780, Loss: 0.8060\n",
      "Epoch 1, Step 7790, Loss: 0.8019\n",
      "Epoch 1, Step 7800, Loss: 0.6774\n",
      "Обучение Reward Model завершено.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. Обучающий цикл с функцией потерь\n",
    "# =============================================================================\n",
    "\n",
    "# Подготавливаем маску для суммирования: создаем матрицу 10x10, где mask[i, j] = 1, если i > j,\n",
    "# что соответствует суммированию p_i(chosen)*p_j(rejected) для всех i > j.\n",
    "mask = torch.tril(torch.ones(10, 10), diagonal=-1).to(device)  # размер: (10,10)\n",
    "\n",
    "print(\"Начало обучения Reward Model с распределением оценок...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        # Извлекаем списки текстов для выбранного и отвергнутого ответов\n",
    "        chosen_texts = batch[\"chosen\"]\n",
    "        rejected_texts = batch[\"rejected\"]\n",
    "\n",
    "        # Токенизируем выбранные и отвергнутые тексты\n",
    "        chosen_encodings = tokenizer_rm(\n",
    "            chosen_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "        rejected_encodings = tokenizer_rm(\n",
    "            rejected_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "        # Переносим на устройство\n",
    "        chosen_encodings = {k: v.to(device) for k, v in chosen_encodings.items()}\n",
    "        rejected_encodings = {k: v.to(device) for k, v in rejected_encodings.items()}\n",
    "\n",
    "        # Прямой проход: получаем логиты для выбранного и отвергнутого ответов\n",
    "        outputs_chosen = model_rm(**chosen_encodings)    # shape: (batch_size, 10)\n",
    "        outputs_rejected = model_rm(**rejected_encodings)  # shape: (batch_size, 10)\n",
    "\n",
    "        logits_chosen = outputs_chosen.logits\n",
    "        logits_rejected = outputs_rejected.logits\n",
    "\n",
    "        # Преобразуем логиты в распределения вероятностей по классам\n",
    "        p_chosen = torch.softmax(logits_chosen, dim=-1)    # shape: (batch_size, 10)\n",
    "        p_rejected = torch.softmax(logits_rejected, dim=-1)  # shape: (batch_size, 10)\n",
    "\n",
    "        # Вычисляем вероятность того, что оценка выбранного ответа выше, чем отвергнутого:\n",
    "        # p_win = sum_{i=0}^{9} sum_{j=0}^{i-1} p_chosen[i] * p_rejected[j]\n",
    "        # Реализуем это в векторизованном виде:\n",
    "        p_chosen_unsq = p_chosen.unsqueeze(2)    # (batch_size, 10, 1)\n",
    "        p_rejected_unsq = p_rejected.unsqueeze(1)  # (batch_size, 1, 10)\n",
    "        prod = p_chosen_unsq * p_rejected_unsq      # (batch_size, 10, 10)\n",
    "        p_win = (prod * mask).view(prod.size(0), -1).sum(dim=1)  # (batch_size,)\n",
    "\n",
    "        # Чтобы избежать log(0), делаем clamp\n",
    "        p_win = p_win.clamp(min=1e-8)\n",
    "\n",
    "        # Функция потерь: усредненное по батчу значение -log(p_win)\n",
    "        loss = - torch.log(p_win).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Step {step}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Обучение Reward Model завершено.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./rm-prob-checkpoints/tokenizer_config.json',\n",
       " './rm-prob-checkpoints/special_tokens_map.json',\n",
       " './rm-prob-checkpoints/vocab.json',\n",
       " './rm-prob-checkpoints/merges.txt',\n",
       " './rm-prob-checkpoints/added_tokens.json',\n",
       " './rm-prob-checkpoints/tokenizer.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_rm.save_pretrained(\"./rm-prob-checkpoints\")\n",
    "tokenizer_rm.save_pretrained(\"./rm-prob-checkpoints\")\n",
    "# Помним, что в Google Colab они сохраняются по факту в \"/content/rm-prob-checkpoints\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE поверх SFT с вероятностной RM\n",
    "Для запуска этого блока нужно запустить только блок с датасетом, потому что RM мы уже сохранили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 0. Загрузка моделей и токенизаторов\n",
    "# =============================================================================\n",
    "# sft_model, tokenizer – SFT модель, которую мы будем дообучать с помощью REINFORCE\n",
    "sft_model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\", padding_side=\"left\")\n",
    "sft_model.to(device)\n",
    "\n",
    "# Загрузим вероятностную RM, обученную ранее (с 10 выходными логитами)\n",
    "# Предполагаем, что модель уже обучена и находится в папке \"rm-prob-checkpoints\"\n",
    "rm_model_path = #YOUR PATH HERE\n",
    "# в случае запуска в Google Colab: \"/content/rm-prob-checkpoints\" \n",
    "model_rm = AutoModelForSequenceClassification.from_pretrained(rm_model_path, num_labels=10)\n",
    "model_rm.to(device)\n",
    "model_rm.eval()  # Для оценки награды – не обновляем RM\n",
    "\n",
    "# Токенизатор для RM\n",
    "tokenizer_rm = AutoTokenizer.from_pretrained(rm_model_path)\n",
    "if tokenizer_rm.pad_token is None:\n",
    "    tokenizer_rm.pad_token = tokenizer_rm.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. Гиперпараметры и оптимизатор (совпадают с Level 1)\n",
    "# =============================================================================\n",
    "\n",
    "batch_size = 4   \n",
    "num_iterations = 30\n",
    "max_new_tokens = 50       # максимальное число генерируемых токенов (отвечает за длину ответа)\n",
    "alpha = 0.9               # коэффициент для moving average baseline\n",
    "learning_rate = 1e-5      # скорость обучения для SFT-модели\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(sft_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. Подготовка DataLoader для датасета\n",
    "# =============================================================================\n",
    "\n",
    "# Используем DataLoader, который выдаёт батчи в виде словаря.\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "data_iter = iter(itertools.cycle(dataloader))  # чтобы можно было бесконечно брать батчи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Вспомогательные функции\n",
    "# =============================================================================\n",
    "\n",
    "def compute_log_prob(prompt, generated_ids):\n",
    "    \"\"\"\n",
    "    Вычисляет суммарную log‑вероятность сгенерированных токенов (исключая prompt).\n",
    "    Для этого:\n",
    "      - Токенизируем prompt, чтобы узнать его длину.\n",
    "      - Пропускаем всю последовательность (prompt + сгенерированный ответ) через модель в режиме teacher forcing.\n",
    "      - Считаем log‑вероятность сгенерированных токенов (начиная с позиции len(prompt)).\n",
    "    \"\"\"\n",
    "    prompt_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    prompt_length = prompt_ids.size(1)\n",
    "\n",
    "    full_ids = generated_ids  # shape: [1, T]\n",
    "    T = full_ids.size(1)\n",
    "    if T - prompt_length <= 0:\n",
    "        return torch.tensor(0.0, device=device)\n",
    "\n",
    "    outputs = sft_model(full_ids)\n",
    "    logits = outputs.logits  # shape: [1, T, vocab_size]\n",
    "    log_probs = torch.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # Сдвигаем последовательность: для токенов с позиции prompt_length ... T-1\n",
    "    pred_logits = log_probs[:, prompt_length - 1:T - 1, :]\n",
    "    target_tokens = full_ids[:, prompt_length:]\n",
    "    token_log_probs = pred_logits.gather(2, target_tokens.unsqueeze(-1)).squeeze(-1)\n",
    "    sum_log_prob = token_log_probs.sum()\n",
    "    return sum_log_prob\n",
    "\n",
    "def compute_expected_reward(text):\n",
    "    \"\"\"\n",
    "    Вычисляет ожидаемое значение оценки, используя вероятностную RM.\n",
    "    Токенизируем текст, пропускаем через RM, применяем softmax и вычисляем:\n",
    "      reward = sum_{i=1}^{10} (i * p_i)\n",
    "    Дополнительно можно вычислить энтропию или дисперсию, если требуется.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        tokenized = tokenizer_rm(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        ).to(device)\n",
    "        outputs = model_rm(**tokenized)  # shape: [1, 10]\n",
    "        logits = outputs.logits  # [1, 10]\n",
    "        probs = torch.softmax(logits, dim=-1)  # [1, 10]\n",
    "        # Оценки от 1 до 10\n",
    "        rating_values = torch.arange(1, 11, device=device).float()  # [10]\n",
    "        expected_reward = (probs * rating_values).sum()  # скаляр\n",
    "    return expected_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало обучения REINFORCE с вероятностной RM...\n",
      "Step 10/30 | Loss: 180.3823 | Avg Reward: 5.4709 | Baseline: 3.4580\n",
      "Step 20/30 | Loss: 61.6600 | Avg Reward: 5.7487 | Baseline: 4.8598\n",
      "Step 30/30 | Loss: 10.1747 | Avg Reward: 4.8728 | Baseline: 5.3448\n",
      "Обучение REINFORCE завершено.\n",
      "Новая модель сохранена в ./sft-rlhf-prob-model\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4. Основной цикл обучения REINFORCE с вероятностной RM\n",
    "# =============================================================================\n",
    "\n",
    "# Инициализируем baseline (moving average) – начнём с 0\n",
    "baseline = 0.0\n",
    "\n",
    "print(\"Начало обучения REINFORCE с вероятностной RM...\")\n",
    "for step in range(num_iterations):\n",
    "    batch = next(data_iter)  # batch — словарь с ключом \"prompt\"\n",
    "\n",
    "    batch_loss = 0.0\n",
    "    batch_rewards = []  # для обновления baseline\n",
    "\n",
    "    # Обрабатываем каждый пример в батче по индексам\n",
    "    for i in range(len(batch[\"prompt\"])):\n",
    "        prompt_text = batch[\"prompt\"][i]\n",
    "\n",
    "        # 1. Генерация ответа SFT-моделью\n",
    "        encoded_prompt = tokenizer(prompt_text, return_tensors=\"pt\", truncation=True).to(device)\n",
    "        generated_ids = sft_model.generate(\n",
    "            input_ids=encoded_prompt.input_ids,\n",
    "            attention_mask=encoded_prompt.attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # 2. Вычисляем log‑вероятность сгенерированного ответа\n",
    "        log_prob = compute_log_prob(prompt_text, generated_ids)\n",
    "\n",
    "        # 3. Вычисляем награду как ожидаемое значение оценки, используя RM\n",
    "        reward_value = compute_expected_reward(generated_text)\n",
    "        batch_rewards.append(reward_value.item())\n",
    "\n",
    "        # 4. Вычисляем Advantage = (reward - baseline)\n",
    "        advantage = reward_value - baseline\n",
    "\n",
    "        # 5. Функция потерь REINFORCE: - advantage * log_prob\n",
    "        sample_loss = - advantage * log_prob\n",
    "        batch_loss = batch_loss + sample_loss\n",
    "\n",
    "    # Усредняем потери по батчу\n",
    "    batch_loss = batch_loss / batch_size\n",
    "\n",
    "    # Обновляем параметры SFT-модели\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Обновляем baseline как скользящее среднее наград\n",
    "    batch_mean_reward = sum(batch_rewards) / len(batch_rewards)\n",
    "    baseline = alpha * baseline + (1 - alpha) * batch_mean_reward\n",
    "\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(f\"Step {step+1}/{num_iterations} | Loss: {batch_loss.item():.4f} | \"\n",
    "              f\"Avg Reward: {batch_mean_reward:.4f} | Baseline: {baseline:.4f}\")\n",
    "\n",
    "print(\"Обучение REINFORCE завершено.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Сохранение новой модели \n",
    "# =============================================================================\n",
    "\n",
    "save_path = \"./sft-rlhf-prob-model\"\n",
    "sft_model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"Новая модель сохранена в {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценим среднюю награду модели на validation наборе\n",
    "Эти ячейки можно запускать независимо от верхних блоков, но при условии запуска ячеек с датасетом. Без запуска блока датасета работать не будет. Здесь используются модели, которые мы уже получили(сохранили) в верхних блоках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя награда RLHF модели с вероятностной RM: 0.33886930197133996\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# путь, где сохранена RM\n",
    "rm_model_path = #YOUR PATH HERE\n",
    "# в случае запуска в Google Colab: \"/content/rm-prob-checkpoints\" \n",
    "model_rm = AutoModelForSequenceClassification.from_pretrained(rm_model_path, num_labels=10)\n",
    "model_rm.to(device)\n",
    "model_rm.eval()  # Для оценки награды – не обновляем RM\n",
    "\n",
    "sft_model = AutoModelForCausalLM.from_pretrained(#YOUR PATH HERE\n",
    "# в случае запуска в Google Colab: \"/content/sft-rlhf-prob-model\"\n",
    "    )\n",
    "tokenizer = AutoTokenizer.from_pretrained(#YOUR PATH HERE\n",
    "# в случае запуска в Google Colab: \"/content/sft-rlhf-prob-model\"\n",
    "                                          , padding_side=\"left\")\n",
    "sft_model.to(device)\n",
    "\n",
    "\n",
    "# Функция для оценки средней награды модели на validation наборе\n",
    "def evaluate_avg_reward(model, tokenizer, dataset, reward_model, reward_tokenizer, max_new_tokens=50):\n",
    "    model.eval()\n",
    "    rewards = []\n",
    "    # Пройдемся по всем примерам в validation наборе (можно ограничить число примеров для ускорения)\n",
    "    for sample in dataset:\n",
    "        prompt_text = sample[\"prompt\"]\n",
    "        encoded = tokenizer(prompt_text, return_tensors=\"pt\", truncation=True).to(device)\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=encoded.input_ids,\n",
    "            attention_mask=encoded.attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        with torch.no_grad():\n",
    "            tokenized_reward = reward_tokenizer(\n",
    "                generated_text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            ).to(device)\n",
    "            reward_output = reward_model(**tokenized_reward)\n",
    "            # Предполагаем, что reward_model возвращает логиты (скаляр)\n",
    "            reward_value = reward_output.logits.mean().item()\n",
    "        rewards.append(reward_value)\n",
    "    avg_reward = sum(rewards) / len(rewards)\n",
    "    return avg_reward\n",
    "\n",
    "# -------------------------------\n",
    "# RLHF модель – текущая sft_model после дообучения REINFORCE\n",
    "# -------------------------------\n",
    "\n",
    "avg_reward_rlhf = evaluate_avg_reward(\n",
    "    model=sft_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=validation_dataset,\n",
    "    reward_model=model_rm,\n",
    "    reward_tokenizer=tokenizer_rm,\n",
    "    max_new_tokens=50\n",
    ")\n",
    "print(\"Средняя награда RLHF модели с вероятностной RM:\", avg_reward_rlhf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обуждение результатов хранится в виде отчета на гите."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
